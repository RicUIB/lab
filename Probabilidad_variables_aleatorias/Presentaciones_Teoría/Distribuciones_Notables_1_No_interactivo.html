<!DOCTYPE html>
<html>
<head>
  <title>Distribuciones Notables Parte I: Distribuciones Discretas</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Distribuciones Notables Parte I: Distribuciones Discretas',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'Distribuciones_Notables_1_No_interactivo_files/logo.gif',
              },

      // Author information
      presenters: [
            {
        name:  'Laboratorio de software y problemas 2. GMAT' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <script src="Distribuciones_Notables_1_No_interactivo_files/header-attrs-2.11/header-attrs.js"></script>
  <link href="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/hammer.js"></script>
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="Distribuciones_Notables_1_No_interactivo_files/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            pre > code.sourceCode { white-space: pre; position: relative; }
            pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
            pre > code.sourceCode > span:empty { height: 1.2em; }
            .sourceCode { overflow: visible; }
            code.sourceCode > span { color: inherit; text-decoration: inherit; }
            div.sourceCode { margin: 1em 0; }
            pre.sourceCode { margin: 0; }
            @media screen {
            div.sourceCode { overflow: auto; }
            }
            @media print {
            pre > code.sourceCode { white-space: pre-wrap; }
            pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
            }
            pre.numberSource code
              { counter-reset: source-line 0; }
            pre.numberSource code > span
              { position: relative; left: -4em; counter-increment: source-line; }
            pre.numberSource code > span > a:first-child::before
              { content: counter(source-line);
                position: relative; left: -1em; text-align: right; vertical-align: baseline;
                border: none; display: inline-block;
                -webkit-touch-callout: none; -webkit-user-select: none;
                -khtml-user-select: none; -moz-user-select: none;
                -ms-user-select: none; user-select: none;
                padding: 0 4px; width: 4em;
                color: #aaaaaa;
              }
            pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
            div.sourceCode
              {   }
            @media screen {
            pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
            }
            code span.al { color: #ff0000; font-weight: bold; } /* Alert */
            code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
            code span.at { color: #7d9029; } /* Attribute */
            code span.bn { color: #40a070; } /* BaseN */
            code span.bu { } /* BuiltIn */
            code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
            code span.ch { color: #4070a0; } /* Char */
            code span.cn { color: #880000; } /* Constant */
            code span.co { color: #60a0b0; font-style: italic; } /* Comment */
            code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
            code span.do { color: #ba2121; font-style: italic; } /* Documentation */
            code span.dt { color: #902000; } /* DataType */
            code span.dv { color: #40a070; } /* DecVal */
            code span.er { color: #ff0000; font-weight: bold; } /* Error */
            code span.ex { } /* Extension */
            code span.fl { color: #40a070; } /* Float */
            code span.fu { color: #06287e; } /* Function */
            code span.im { } /* Import */
            code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
            code span.kw { color: #007020; font-weight: bold; } /* Keyword */
            code span.op { color: #666666; } /* Operator */
            code span.ot { color: #007020; } /* Other */
            code span.pp { color: #bc7a00; } /* Preprocessor */
            code span.sc { color: #4070a0; } /* SpecialChar */
            code span.ss { color: #bb6688; } /* SpecialString */
            code span.st { color: #4070a0; } /* String */
            code span.va { color: #19177c; } /* Variable */
            code span.vs { color: #4070a0; } /* VerbatimString */
            code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
        
    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(Distribuciones_Notables_1_No_interactivo_files/logo.gif) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>

  <link rel="stylesheet" href="Mery_style.css" type="text/css" />

</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="Distribuciones_Notables_1_No_interactivo_files/logo.gif"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribuciones Notables I</h2></hgroup><article  id="distribuciones-notables-i">

</article></slide><slide class=""><hgroup><h2>Introducción</h2></hgroup><article  id="introducción">

<ul>
<li><p>En este tema estudiaremos diversos tipos de experimentos que son muy frecuentes y algunas de las variables aleatorias asociadas a ellos.</p></li>
<li><p>Estas variables reciben distintos nombres que aplicaremos sin distinción al tipo de población del experimento a la variable o a su función de probabilidad, densidad o distribución.</p></li>
<li><p>Empezaremos con las variables aleatorias discretas que se presentan con frecuencia ya que están relacionadas con situaciones muy comunes como el número de caras en varios lanzamiento de una moneda, el número de veces que una maquina funciona hasta que se estropea, el numero de clientes en una cola,…</p></li>
</ul>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribución Bernoulli</h2></hgroup><article  id="distribución-bernoulli">

</article></slide><slide class=""><hgroup><h2>Distribución Bernoulli</h2></hgroup><article  id="distribución-bernoulli-1">

<p><l class="definition"> Distribución Bernoulli </l></p>

<ul>
<li>Consideremos un experimento con dos resultados posibles éxito (E) y fracaso (F). El espacio de sucesos será \(\Omega=\{E,F\}\).</li>
<li>Supongamos que la probabilidad de éxito es \(P(E)=p\), y naturalmente \(P(F)=1-p=q\) con \(0&lt;p&lt;1\).</li>
<li>Consideremos la aplicación</li>
</ul>

<p>\[
X:\Omega=\{E,F\}\to \mathbb{R}
\]</p>

<p>definida por</p>

<p>\[
X(E)=1\mbox{, }X(F)=0.
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución Bernoulli</h2></hgroup><article  id="distribución-bernoulli-2">

<p>Su función de probabilidad es</p>

<p>\[
P_{X}(x)=
\left\{
\begin{array}{ll} 1-p=q &amp; \mbox{si } x=0\\
p &amp; \mbox{si } x=1\\
0 &amp; \mbox{en cualquier otro caso}
\end{array}
\right..
\]</p>

<p>Su función de distribución es</p>

<p>\[
F_{X}(x)=P(X\leq x)=
\left\{
\begin{array}{ll} 
0 &amp; \mbox{si } x&lt;0\\
1-p=q &amp; \mbox{si } 0\leq x &lt;1\\
1 &amp; \mbox{si } 1\leq x \\
\end{array}
\right..
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución Bernoulli</h2></hgroup><article  id="distribución-bernoulli-3">

<ul>
<li>Bajo estas condiciones diremos que \(X\) <strong>es una v.a. Bernoulli</strong> o que sigue una ley de <strong>distribución de probabilidad Bernoulli</strong> de parámetro \(p\).</li>
<li>Lo denotaremos por \[X\equiv Ber(p)\mbox{ o también } X\equiv B(1,p).\]</li>
<li>A este tipo de experimentos (éxito/fracaso)se les denomina experimentos Bernoulli.</li>
<li>Fue su descubridor un científico suizo <a href='https://es.wikipedia.org/wiki/Jakob_Bernoulli' title=''>Jacob Bernoulli</a>, uno más de la de la conocida <a href='https://es.wikipedia.org/wiki/Familia_Bernoulli' title=''>familia de científicos suizos Bernoulli</a></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Esperanza de una v.a. \(X\) \(Ber(p)\)</h2></hgroup><article  id="esperanza-de-una-v.a.-x-berp">

<p>Su <strong>valor esperado</strong> es</p>

<p>\[E(X)=\displaystyle\sum_{x=0}^1 x\cdot P(X=x)= 0\cdot(1-p)+1\cdot p=p.\]</p>

<p>Calculemos también \(E(X^2)\)</p>

<p>\[E(X^2)=\displaystyle\sum_{x=0}^1 x^2\cdot P(X=x)= 0^2\cdot(1-p)+1^2\cdot p=p.\]</p>

</article></slide><slide class=""><hgroup><h2>Varianza de una v.a. \(X\) \(Ber(p)\)</h2></hgroup><article  id="varianza-de-una-v.a.-x-berp">

<p>Su <strong>varianza</strong> es</p>

<p>\[Var(X)=E(X^2)-\left(E(X)\right)^2=p-p^2=p\cdot (1-p)=p\cdot q.\]</p>

<p>Su desviación típica es</p>

<p>\[
\sqrt{Var(X)}=\sqrt{p \cdot (1-p)}.
\]</p>

</article></slide><slide class=""><hgroup><h2>Resumen v.a con distribución Bernoulli</h2></hgroup><article  id="resumen-v.a-con-distribución-bernoulli">

<table class = 'rmdtable'>
<col width="55.000000%" />
<col width="45.000000%" />
<tr class="header">
<th align="right">\(X\) Bernoulli</th>
<th align="left">\(Ber(p)\)</th>
</tr>
<tr class="odd">
<td align="right">\(D_X=\)</td>
<td align="left">\(\{0,1\}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(x)=P(X=x)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} q &amp; \mbox{si } x=0\\ p &amp; \mbox{si } x=1\\0 &amp; \mbox{en otro caso}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq X)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} 0 &amp; \mbox{ si } x&lt;0\\q &amp; \mbox{ si } 0\leq x&lt;1\\1 &amp; \mbox{ si } 1\leq x \end{array}\right.\)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=p\)</td>
<td align="left">\(Var(X)=p\cdot q\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Distribución Bernoulli. Ejemplo</h2></hgroup><article  id="distribución-bernoulli.-ejemplo">

<p>Veamos los cálculos básicos \(Ber(p=0.25)\) en <code>R</code>.</p>

<pre class = 'prettyprint lang-r'>dbinom(0,size=1,prob=0.25)</pre>

<pre >## [1] 0.75</pre>

<pre class = 'prettyprint lang-r'>dbinom(1,size=1,prob=0.25)</pre>

<pre >## [1] 0.25</pre>

<pre class = 'prettyprint lang-r'>rbinom(n=20,size = 1,prob=0.25)</pre>

<pre >##  [1] 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0</pre>

</article></slide><slide class=""><hgroup><h2>Distribución Bernoulli. Ejemplo</h2></hgroup><article  id="distribución-bernoulli.-ejemplo-1">

<p>El siguiente código dibuja las función de probabilidad y la de distribución de una \(Ber(p=0.25)\)</p>

<pre class = 'prettyprint lang-r'>par(mfrow=c(1,2))
plot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=0.25),
     ylim=c(0,1),xlim=c(-1,2),xlab=&quot;x&quot;,
     main=&quot;Función de probabilidad\n Ber(p=0.25)&quot;)
lines(x=c(0,0,1,1),y=c(0,0.75,0,0.25), type = &quot;h&quot;, lty = 2,col=&quot;blue&quot;)
curve(pbinom(x,size=1,prob=0.25),
      xlim=c(-1,2),col=&quot;blue&quot;,
      main=&quot;Función de distribución\n Ber(p=0.25)&quot;)
par(mfrow=c(1,1))</pre>

</article></slide><slide class=""><hgroup><h2>Distribución Bernoulli. Ejemplo</h2></hgroup><article  id="distribución-bernoulli.-ejemplo-2">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficas interactivas \(Ber(p)\)</h2></hgroup><article  id="gráficas-interactivas-berp">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

<p>O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a></p>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribución binomial</h2></hgroup><article  id="distribución-binomial">

</article></slide><slide class=""><hgroup><h2>Distribución binomial</h2></hgroup><article  id="distribución-binomial-1">

<p><l class=definition> Distribución binomial </l></p>

<p>Si repetimos \(n\) veces de forma independiente un experimento Bernoulli de parámetro \(p\).</p>

<p>El espacio muestral \(\Omega\) estará formado por cadenas de \(E\)’s y \(F\)’s de longitud \(n\) Consideremos la v.a.</p>

<p>\[X(\overbrace{EFFF\ldots EEF}^{n})=\mbox{número de éxitos en la cadena}.\] A la variable aleatoria anterior se le conoce como distribución binomial de parámetros \(n\) y \(p\), y lo denotaremos por \(X\equiv B(n,p).\)</p>

</article></slide><slide class=""><hgroup><h2>Función de probabilidad de una binomial</h2></hgroup><article  id="función-de-probabilidad-de-una-binomial">

<p>Entonces su <strong>función de probabilidad</strong> es</p>

<p>\[
P_{X}(x)=\left\{
\begin{array}{ll}
{n\choose x}\cdot  p^x \cdot(1-p)^{n-x} &amp;\mbox{ si } x=0,1,\ldots,n\\
0  &amp; \mbox{ en otro caso}
\end{array}\right..
\]</p>

</article></slide><slide class=""><hgroup><h2>Función de distribución de binomial</h2></hgroup><article  id="función-de-distribución-de-binomial">

<p>Su <strong>función de distribución</strong> no tiene una fórmula cerrada. Hay que acumular la función de probabilidad:</p>

<p>\[
\begin{eqnarray*}
F_{X}(x)=P(X\leq x) &amp; = &amp; \sum_{i=0}^x P_X(i)\\
&amp; = &amp; 
\left\{
\begin{array}{ll}
0 &amp; \mbox{ si } x&lt;0\\\displaystyle
\sum_{i=0}^k {n\choose i}\cdot  p^i \cdot (1-p)^{n-i} &amp; \mbox{ si } 
\left\{
  \begin{array}{l} 
  k\leq x&lt; k+1\\
  k=0,1,\ldots,n.
  \end{array}
\right.\\
1 &amp; \mbox{ si } n\leq x
\end{array}
\right.
\end{eqnarray*}
\]</p>

</article></slide><slide class=""><hgroup><h2>Números binomiales con R</h2></hgroup><article  id="números-binomiales-con-r">

<p>Los números binomiales calculan el número de equipos de baloncesto distintos que (\(k=5\) jugadores) se pueden hacer con 6 jugadores (\(n=6\)).</p>

<p>Es decir cuántas maneras distintas hay para elegir (<em>choose</em>) 5 jugadores en un conjunto de 6 jugadores. Todo el mundo diría ¡¡¡6!!!. Efectivamente con R es</p>

<pre class = 'prettyprint lang-r'>choose(6,5)</pre>

<pre >## [1] 6</pre>

</article></slide><slide class=""><hgroup><h2>Números binomiales con R</h2></hgroup><article  id="números-binomiales-con-r-1">

<p>Con 10 jugadores el número de equipos de 5 distintos es bastante más grande</p>

<pre class = 'prettyprint lang-r'>choose(10,5)</pre>

<pre >## [1] 252</pre>

<p>Y, por ejemplo, con un equipo de fútbol profesional que tiene en plantilla 22 jugadores (quitando los guardametas) se pueden formar ¡¡nada menos que!!</p>

<pre class = 'prettyprint lang-r'>choose(22,10)</pre>

<pre >## [1] 646646</pre>

<p>un bonito número capicúa que nos da el número de equipos distintos que se pueden formar.</p>

</article></slide><slide class=""><hgroup><h2>Distribución Binomial</h2></hgroup><article  id="distribución-binomial-2">

<p>Obviamente se tiene que una v.a. Bernoulli es una binomial con \(n=1\)</p>

<p>\[B(1,p)=Ber(p).\]</p>

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Calculad las funciones de distribución de una binomial \(B(n=1,p=0.3)\) y comprobar que coinciden con las distribuciones de una \(Ber(p=0.3)\).</p></div>

</article></slide><slide class=""><hgroup><h2>Observaciones sobre la distribución binomial</h2></hgroup><article  id="observaciones-sobre-la-distribución-binomial">

<ul>
<li>La probabilidad de fracaso se suele denotar con \(q=1-p\), <strong>sin ningún aviso adicional</strong>, con el fin de acortar y agilizar la escritura de las fórmulas.</li>
<li>Su <strong>función de distribución no tienen una formula general</strong>, hay que calcularla con una función de R o python… En el siglo pasado se tabulaban en los libros de papel :-).</li>
<li>En el material adicional os pondremos unas tablas de esta distribución para distintos valores de \(n\) y \(p\) para que disfrutéis de tan ancestral método de cálculo.</li>
<li>Cualquier paquete estadístico, hoja de cálculo dispone de funciones para el cálculo de estas probabilidades, así que el <strong>uso de las tablas</strong> queda <strong>totalmente anticuado</strong>.</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Esperanza de una \(B(n,p)\)</h2></hgroup><article  id="esperanza-de-una-bnp">

<p>Su <strong>esperanza</strong> es \[E(X)=\displaystyle\sum_{k=0}^n k \cdot  {n \choose k }\cdot p^k\cdot q^{n-k} = n\cdot p.\]</p>

<p>La esperanza de \(X^2\) es</p>

<p>\[
\begin{eqnarray*}
E(X^2)&amp;=&amp; \displaystyle\sum_{k=0}^n k^2 \cdot  {n \choose k }\cdot p^k\cdot q^{n-k}\\
&amp;=&amp; n\cdot p\cdot q+(n\cdot p)^2.
\end{eqnarray*}
\]</p>

</article></slide><slide class=""><hgroup><h2>Varianza de una \(B(n,p)\)</h2></hgroup><article  id="varianza-de-una-bnp">

<p>Su <strong>varianza</strong> es</p>

<p>\[Var(X)=E(X^2)-\left(E(X)\right)^2=n\cdot p \cdot q=n\cdot p\cdot (1-p).\]</p>

<p>Su desviación típica es</p>

<p>\[\sqrt{n\cdot p\cdot q}=\sqrt{n\cdot p\cdot (1-p)}.\]</p>

<p>En temas posteriores veremos una forma sencilla del cálculo de la esperanza y varianza de una \(B(n,p)\) como las suma de \(n\) v.a. \(Ber(p)\) independientes.</p>

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Justificar de forma intuitiva que si \(X_i\) con \(i=1,2,\ldots, n\) son v.a. \(Ber(p)\) independientes entonces \(X=\displaystyle\sum_{i=1}^n X_i\) sigue una distribución \(B(n,p).\)</p></div>

</article></slide><slide class=""><hgroup><h2>Resumen v.a con distribución binomial \(B(n,p)\)</h2></hgroup><article  id="resumen-v.a-con-distribución-binomial-bnp">

<table class = 'rmdtable'>
<col width="60.869565%" />
<col width="39.130435%" />
<tr class="header">
<th align="right">\(X\) binomial</th>
<th align="left">\(B(n,p)\)</th>
</tr>
<tr class="odd">
<td align="right">\(D_X=\)</td>
<td align="left">\(\{0,1,\ldots n\}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(x)=P(X=x)=\)</td>
<td align="left">\(\left\{\begin{array}{ll}{n\choose x}\cdot p^x\cdot (1-p)^{n-x} &amp; \mbox{ si } x=0,1,\ldots,n\\0 &amp; \mbox{ en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq X)=\)</td>
<td align="left">no tiene fórmula (utilizad funciones de <code>R</code> o python)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=\)</td>
<td align="left">\(n\cdot p\)</td>
</tr>
<tr class="odd">
<td align="right">\(Var(X)=\)</td>
<td align="left">\(n\cdot p \cdot (1-p)\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Cálculos binomial con R</h2></hgroup><article  id="cálculos-binomial-con-r">

<p>Veamos los cálculos básicos con funciones de R para una v.a \(X\) con distribución binomial \(B(n=10,p=0.25)\).</p>

<p>Si queremos calcular con <code>R</code> algún valor de la función de distribución como por ejemplo \(F_X(0)=P(X\leq 0)\), tenemos que hacer:</p>

<pre class = 'prettyprint lang-r'>pbinom(0,size=10,prob=0.25)</pre>

<pre >## [1] 0.05631351</pre>

<p>y si queremos por ejemplo \(F_X(4)=P(X\leq 4)\), tenemos que hacer:</p>

<pre class = 'prettyprint lang-r'>pbinom(4,size=10,prob=0.25)</pre>

<pre >## [1] 0.9218731</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos binomial con R</h2></hgroup><article  id="cálculos-binomial-con-r-1">

<p>Sin embargo, si queremos calcular algún valor de la función de probabilidad como por ejemplo \(P(X=0)\), tenemos que hacer:</p>

<pre class = 'prettyprint lang-r'>dbinom(0,size=10,prob=0.25)</pre>

<pre >## [1] 0.05631351</pre>

<p>o por ejemplo para \(P(X=4)\):</p>

<pre class = 'prettyprint lang-r'>dbinom(4,size=10,prob=0.25)</pre>

<pre >## [1] 0.145998</pre>

</article></slide><slide class=""><hgroup><h2>Generación de muestras aleatorias con R</h2></hgroup><article  id="generación-de-muestras-aleatorias-con-r">

<p>Generaremos una muestra aleatoria de 100 valores de una población con distribución \(B(20,0.5)\)</p>

<pre class = 'prettyprint lang-r'>set.seed(2019)
rbinom(100,size = 20,prob=0.5)</pre>

<pre >##   [1] 12 11  9 11  6  6 12  5  7 11 12 11  8  8 11 11  7 11  9 10  9 10 14  8  8
##  [26]  5 11 14 11 10 11  5 12  8  6  7  9 10  5 12 11  9 12 11 12 10 13 13  8  8
##  [51]  9  7  6  9 10  9 16 13  6  6  8  8 11  9 12 15  9  7 12 11  9  8  9  8 11
##  [76] 15  7 10  9 12  6 13 14  8 10  8 10 11 11  9 10 11 12  8 10 12  9 13  9 13</pre>

<div class="example">
<p><strong>Ejemplo</strong></p>

<p>El ejemplo anterior correspondería a repetir 100 veces el experimento de lanzar una moneda 20 veces y contar el número de caras.</p>

</article></slide><slide class=""><hgroup><h2>Cálculos distribución binomial con python</h2></hgroup><article  id="cálculos-distribución-binomial-con-python">

<p>Veamos los cálculos básicos con funciones de python para una v.a \(X\) con distribución binomial \(B(n=10,p=0.25)\).</p>

<p>Primero importamos la función <code>binom</code> de la librería <code>scipy.stat</code></p>

<pre class = 'prettyprint lang-python'>from scipy.stats import binom</pre>

<p>En general en el paquete <code>scipy</code>, la función de probabilidad se invocará con el método <code>pmf</code>, la de distribución con el método <code>cdf</code> mientras que una muestra aleatoria que siga esta distribución con el método <code>rvs</code>. En todos ellos aparecerá siempre el parámetro <code>loc</code> que se utiliza para desplazar el dominio de la variable aleatoria. Por ejemplo, en este caso</p>

<pre class = 'prettyprint lang-python'>binom.pmf(k, n, p, loc) =  binom.pmf(k - loc, n, p)</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos distribución binomial con python</h2></hgroup><article  id="cálculos-distribución-binomial-con-python-1">

<p>Para calcular los valores de la función de distribución como por ejemplo \(F_X(0)=P(X\leq 0)\) y \(F_X(4)=P(X\leq 4)\) utilizamos la función <code>cdf</code></p>

<pre class = 'prettyprint lang-python'>binom.cdf(0,n=10,p=0.25)</pre>

<pre >## 0.056313514709472656</pre>

<pre class = 'prettyprint lang-python'>binom.cdf(4,n=10,p=0.25)</pre>

<pre >## 0.9218730926513672</pre>

<p>Notemos que al no indicar el valor de <code>loc</code>, se le asume que toma el valor 0.</p>

</article></slide><slide class=""><hgroup><h2>Cálculos distribución binomial con python</h2></hgroup><article  id="cálculos-distribución-binomial-con-python-2">

<p>Para calcular los valores de la función de probabilidad \(P(X=0)\) y \(P(X=4)\) utilizamos la función <code>pmf</code>:</p>

<pre class = 'prettyprint lang-python'>binom.pmf(0,n=10,p=0.25)</pre>

<pre >## 0.056313514709472684</pre>

<pre class = 'prettyprint lang-python'>binom.pmf(4,n=10,p=0.25)</pre>

<pre >## 0.14599800109863295</pre>

<p>Notemos que al no indicar el valor de <code>loc</code>, se le asume que toma el valor 0.</p>

</article></slide><slide class=""><hgroup><h2>Cálculos distribución binomial con python</h2></hgroup><article  id="cálculos-distribución-binomial-con-python-3">

<p>Si queremos generar una muestras aleatorias que siga una distribución binomial, podemos usar la función <code>rvs</code>. En este caso, generaremos una muestra aleatoria de 100 valores de una población \(B(20,0.5)\)</p>

<pre class = 'prettyprint lang-python'>binom.rvs(n=20,p=0.25,size = 100)</pre>

<pre >## array([2, 7, 1, 5, 2, 6, 9, 3, 9, 6, 3, 7, 5, 5, 8, 3, 1, 5, 9, 5, 6, 4,
##        4, 6, 5, 6, 6, 3, 8, 4, 3, 7, 6, 6, 7, 2, 4, 4, 7, 8, 9, 4, 7, 7,
##        5, 7, 4, 5, 7, 6, 5, 8, 3, 3, 5, 3, 3, 5, 4, 5, 5, 3, 8, 4, 7, 8,
##        5, 2, 4, 3, 7, 5, 4, 4, 4, 9, 3, 4, 6, 4, 3, 4, 7, 7, 4, 5, 7, 3,
##        6, 5, 4, 2, 4, 7, 5, 6, 4, 2, 6, 6])</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos distribución binomial con python</h2></hgroup><article  id="cálculos-distribución-binomial-con-python-4">

<p><l class="observ"> Observación</l> Notemos que la secuencia aleatoria generada no es la misma que con <code>R</code>. De hecho, si volvemos a ejecutar esta función obtendremos una muestra aleatoria distinta.</p>

<pre class = 'prettyprint lang-python'>binom.rvs(n=20,p=0.25,size = 100)</pre>

<pre >## array([8, 5, 3, 3, 6, 5, 7, 3, 5, 2, 7, 2, 5, 7, 3, 3, 5, 5, 3, 4, 5, 3,
##        8, 7, 5, 8, 6, 6, 7, 8, 5, 4, 4, 5, 1, 8, 4, 3, 5, 3, 6, 6, 4, 5,
##        4, 3, 1, 7, 8, 5, 7, 3, 1, 5, 3, 6, 3, 6, 6, 3, 5, 4, 3, 3, 5, 4,
##        3, 6, 4, 3, 4, 2, 5, 4, 3, 4, 7, 4, 6, 4, 9, 6, 6, 5, 2, 7, 5, 8,
##        6, 3, 8, 4, 3, 8, 4, 2, 6, 2, 3, 5])</pre></div>

</article></slide><slide class=""><hgroup><h2>Cálculos binomial con python</h2></hgroup><article  id="cálculos-binomial-con-python">

<p>Veamos algunos cálculos básicos con funciones de python para la binomial \(B(n=10,p=0.25)\).</p>

<pre class = 'prettyprint lang-python'>binom.cdf(5,n=10,p=0.25)</pre>

<pre >## 0.9802722930908203</pre>

<pre class = 'prettyprint lang-python'>binom.pmf(1,n=10,p=0.25)</pre>

<pre >## 0.18771171569824247</pre>

<pre class = 'prettyprint lang-python'>binom.rvs(n=20,p=0.25,size=10)</pre>

<pre >## array([5, 4, 5, 7, 5, 8, 3, 3, 6, 6])</pre>

</article></slide><slide class=""><hgroup><h2>Gráficas de la distribución binomial con R</h2></hgroup><article  id="gráficas-de-la-distribución-binomial-con-r">

<p>El siguiente código de R dibuja las función de probabilidad y la de distribución de una \(B(n=10,p=0.25)\)</p>

<pre class = 'prettyprint lang-r'>par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dbinom(c(0:10),size=10,prob=0.25)
plot(x=c(0:10),y=dbinom(c(0:10),size=10,prob=0.25),
  ylim=c(0,1),xlim=c(-1,11),xlab=&quot;x&quot;,
  main=&quot;Función de probabilidad\n B(n=10,p=0.25)&quot;)
lines(x=rep(0:10,each=2),y=aux, type = &quot;h&quot;, lty = 2,col=&quot;blue&quot;)
curve(pbinom(x,size=10,prob=0.25),
  xlim=c(-1,11),col=&quot;blue&quot;,
  main=&quot;Función de distribución\n B(n=10,p=0.25)&quot;)
par(mfrow=c(1,1))</pre>

</article></slide><slide class=""><hgroup><h2>Gráficas de la distribución binomial con R</h2></hgroup><article  id="gráficas-de-la-distribución-binomial-con-r-1">

<p>El siguiente código de R dibuja las función de probabilidad y la de distribución de una \(B(n=10,p=0.25)\)</p>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficas interactivas binomial</h2></hgroup><article  id="gráficas-interactivas-binomial">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a></p>

</article></slide><slide class=""><hgroup><h2>Gráficos de la distribución binomial con python</h2></hgroup><article  id="gráficos-de-la-distribución-binomial-con-python">

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Buscad en la documentación de python cómo se dibuja la función de probabilidad y de distribución de una binomial y recread los gráficos anteriores.</p></div>

<div class="exercise-sol">
<p>Pista: Necesitaremos investigar más librerías:</p>

<pre class = 'prettyprint lang-python'>import numpy as np
import matplotlib.pyplot as plt</pre></div>

</article></slide><slide class=""><hgroup><h2>Gráficos de la distribución binomial con python</h2></hgroup><article  id="gráficos-de-la-distribución-binomial-con-python-1">

<pre class = 'prettyprint lang-python'>n, p = 10, 0.25
x = np.arange(binom.ppf(0.01, n, p),binom.ppf(0.99, n, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, binom.pmf(x, n, p), &#39;bo&#39;, ms=8, label=&#39;binom pmf&#39;)
ax.vlines(x, 0, binom.pmf(x, n, p), colors=&#39;b&#39;, lw=5, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, binom.cdf(x, n, p), &#39;bo&#39;, ms=8, label=&#39;binom pmf&#39;)
ax.vlines(x, 0, binom.cdf(x, n, p), colors=&#39;b&#39;, lw=5, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle(&#39;Distribucion Binomial&#39;)
plt.show()</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos de la distribución binomial con python</h2></hgroup><article  id="gráficos-de-la-distribución-binomial-con-python-2">

<div class="center">
<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/dibu_python2-1.png" width="480" /><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/dibu_python2-2.png" width="480" /></p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo distribución binomial</h2></hgroup><article  id="ejemplo-distribución-binomial">

<div class="example">
<p><strong>Ejemplo: número de bolas rojas extraídas de una urna con reposición</strong></p>

<p>Tenemos una urna con \(100\) bolas de las cuales 40 son rojas y 60 son blancas. Extraemos al azar una bola, anotamos su color y la devolvemos a (reponemos en) la urna.</p>

<p>Supongamos que repetimos este proceso \(n=10\) reponiendo en cada ocasión la bola extraída.</p>

<p>Consideremos la variable aleatoria \(X\) como el número de bolas rojas extraídas (con reposición) en \(n=10\) repeticiones del mismo experimento de Bernoulli.</p>

<p>Bajo estas condiciones repetimos \(n=10\) veces el mismo experimento de Bernouilli con probabilidad de éxito (sacar bola roja) \[P(Roja)=P(Éxito)=p=\frac{40}{100}=0.4.\]</p>

<p>Así que la variable \(X\) que es el número de bolas rojas extraídas de la urna (con reposición) en \(n=10\) ocasiones sigue una ley binomial \(B(n=10,p=0.4).\)</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.">

<div class="example">
<p>Nos preguntamos:</p>

<ol>
<li>¿Cuál es la probabilidad de que saquemos exactamente \(4\) bolas rojas?</li>
<li>¿Cuál es la probabilidad de que saquemos al menos \(4\) bolas rojas?</li>
<li>¿Cuál es la probabilidad de que saquemos menos de \(3\) bolas rojas?</li>
<li>¿Cuál es el valor esperado del número de bolas rojas?</li>
<li>¿Cuál es la desviación típica del número de bolas rojas?</li>
</ol></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-1">

<div class="example-sol">
<p><strong>Solución 1</strong>. ¿Cuál es la probabilidad de que saquemos exactamente \(4\) rojas?</p>

<p>Utilizando la función de probabilidad, tenemos que: </p>

<p>Con R</p>

<pre class = 'prettyprint lang-r'>dbinom(4,size=10,prob = 0.4)</pre>

<pre >## [1] 0.2508227</pre></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-2">

<div class="example-sol">
<p><strong>Solución 2</strong>. ¿Cuál es la probabilidad de que saquemos al menos \(4\) bolas rojas?</p>

<p>La probabilidad de sacar al menos 4 rojas se expresa como</p>

<p>\(P(X \geq 4)=1-P(X&lt;4)=1-P(X\leq 3):\)</p>

<p>\[
\begin{eqnarray*}
P(x\leq 3)&amp;=&amp; P(X=0)+P(X=1)+P(X=2)+P(X=3)\\
&amp;=&amp; 
 {10\choose 0}\cdot 0.4^0\cdot (1-0.4)^{10-0}+ {10\choose 1}\cdot 0.4^1\cdot (1-0.4)^{10-1}\\
&amp;+&amp;{10\choose 2}\cdot 0.4^2\cdot (1-0.4)^{10-2}+ {10\choose 3}\cdot 0.4^3\cdot (1-0.4)^{10-3}\\
&amp;=&amp;0.3822806.
\end{eqnarray*}
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-3">

<div class="example-sol">
<p>Con <code>R</code></p>

<pre class = 'prettyprint lang-r'>pbinom(3,10,0.4)</pre>

<pre >## [1] 0.3822806</pre>

<p>Así que</p>

<p>\[P(X \geq 4 )=1-P(X&lt; 4)=1-P(X\leq 3)=1-0.3822806=0.6177194.\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-4">

<div class="example-sol">
<p>Otra manera usando <code>R</code> sería:</p>

<pre class = 'prettyprint lang-r'>1-pbinom(3,10,0.4)</pre>

<pre >## [1] 0.6177194</pre>

<p>Aunque en estos casos el parámetro <code>lower.tail = FALSE</code> es sin duda nuestra mejor opción:</p>

<pre class = 'prettyprint lang-r'>pbinom(3,10,0.4,lower.tail = FALSE)</pre>

<pre >## [1] 0.6177194</pre></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-5">

<div class="example-sol">
<p><strong>Solución 3</strong>. ¿Cuál es la probabilidad de que saquemos menos de \(3\) bolas rojas?</p>

<p></p>

<p>En <code>R</code>:</p>

<pre class = 'prettyprint lang-r'>dbinom(0,10,0.4)+dbinom(1,10,0.4)+dbinom(2,10,0.4)</pre>

<pre >## [1] 0.1672898</pre>

<pre class = 'prettyprint lang-r'>pbinom(2,10,0.4)</pre>

<pre >## [1] 0.1672898</pre></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-6">

<div class="example-sol">
<p><strong>Solución 4</strong>. ¿Cuál es el valor esperado del número de bolas rojas?</p>

<p>Como \(X\) es una \(B(n=10,p=0.4)\) sabemos que</p>

<p>\[E(X)=n\cdot p = 10\cdot 0.4=4.\]</p>

<p>Aunque en python tenemos la función <code>stats</code> que nos lo calcula directamente:</p>

<pre class = 'prettyprint lang-python'>print(&quot;E(X) = {m}&quot;.format(m=binom.stats(n = 10, p = 0.4, moments=&#39;m&#39;)))</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-17-1.png" width="480" /></p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(B(n=10,p=0.4).\)</h2></hgroup><article  id="ejemplo-bn10p0.4.-7">

<div class="example-sol">
<p><strong>Solución 5</strong>. ¿Cuál es la desviación típica del número de bolas rojas?</p>

<p>La varianza es: \[
Var(X)=n\cdot p \cdot(1-p)=10\cdot 0.4\cdot 0.6=2.4.
\]</p>

<p>Por lo tanto la desviación típica es</p>

<p>\[\sqrt{Var(X)}=\sqrt{2.4}= 1.5491933.\]</p>

<p>Aunque en python tenemos la función <code>stats</code> que nos lo calcula directamente:</p>

<pre class = 'prettyprint lang-python'>print(&quot;Var(X) = {v}&quot;.format(v=binom.stats(n = 10, p = 0.4, moments=&#39;v&#39;)))</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-18-3.png" width="480" /></p></div>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribución geométrica</h2></hgroup><article  id="distribución-geométrica">

</article></slide><slide class=""><hgroup><h2>Distribución geométrica</h2></hgroup><article  id="distribución-geométrica-1">

<ul>
<li><p>Todos hemos jugado a, por ejemplo, tirar una moneda hasta que obtengamos la primera cara.</p></li>
<li><p>O también tirar una pelota a una canasta de baloncesto hasta obtener la primera canasta.</p></li>
<li><p>Desde otro punto de vista también podemos intentar modelar el número de veces que accionamos una interruptor y la bombilla se ilumina hasta que falla.</p></li>
<li><p>O también el número de veces que un cajero automático nos da dinero hasta que falla.</p></li>
</ul>

<p>La <strong>modelización de este tipo de problemas se consigue con la llamada distribución geométrica</strong>.</p>

</article></slide><slide class=""><hgroup><h2>Distribución geométrica</h2></hgroup><article  id="distribución-geométrica-2">

<p><l class="definition"> Distribución geométrica </l></p>

<ul>
<li>Repitamos un experimento Bernoulli, de parámetro \(p\), de forma independiente hasta obtener el primer éxito.</li>
<li>Sea \(X\) la v.a. que cuenta el número de fracasos antes del primer éxito. Por ejemplo que hayamos tenido \(x\) fracasos será una cadena de \(x\) fracasos culminada con un éxito. Más concretamente</li>
</ul>

<p>\[P(\overbrace{FFF\ldots F}^{x}E)=P(F)^{x}\cdot P(E)=(1-p)^{x}\cdot p=q^{x}\cdot p.\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución geométrica</h2></hgroup><article  id="distribución-geométrica-3">

<p>Su función de probabilidad es</p>

<p>\[
P_X(x)=P(X=x)=\left\{\begin{array}{ll}
(1-p)^{x}\cdot p &amp; \mbox{ si } x=0,1,2,\ldots\\
0 &amp;\mbox{ en otro caso}
\end{array}\right..
\]</p>

<ul>
<li>La v.a. definida anteriormente diremos que sigue una distribución geométrica de parámetro \(p\).</li>
<li>La denotaremos por \(Ge(p)\).</li>
<li>Su dominio es \(D_X=\{0,1,2,\ldots\}\).</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Función de distribución geométrica</h2></hgroup><article  id="función-de-distribución-geométrica">

<p>Calculemos P(\(X\leq 3\)).</p>

<p>Por la propiedad de la probabilidad del suceso complementario tenemos que</p>

<p>\[
P(X\leq 3 )=1-P(X&gt; 3)=1-P(X\geq 4)
\]</p>

<p>Efectivamente, el complementario del evento \(X\leq 3\) nos dice que hemos fracasado más de tres veces hasta conseguir el primer éxito, es decir, <strong>hemos fracasado 4 o más veces</strong>. Podemos simbolizar dicho evento de la forma siguiente: \[
\{X&gt;3\}=\{X\geq 4\}= \{FFFF\}
\]</p>

</article></slide><slide class=""><hgroup><h2>Función de distribución geométrica</h2></hgroup><article  id="función-de-distribución-geométrica-1">

<p>Ahora, al ser los intentos independientes, tenemos que:</p>

<p>\[
\begin{eqnarray*}
P(X&gt;3) &amp; = &amp; P(\{FFFF\})= P(F)\cdot P(F)\cdot P(F)\cdot P(F)\\
&amp;=&amp; (1-p)\cdot (1-p)\cdot (1-p)\cdot (1-p)= (1-p)^{3+1}\\\
&amp;=&amp;(1-p)^{4}.
\end{eqnarray*}
\]</p>

<p>El valor de la función de distribución de \(X\) en \(x=3\) será, pues: \[F_X(3)=P(X\leq 3)=1-P(X&gt;3)=1-(1-p)^{3+1}.\] Generalizando el resultado anterior a cualquier entero positivo \(k=0,1,2,\ldots\), tenemos: \[F_X(k)=P(X\leq k)=1-(1-p)^{k+1},\mbox{ si } k=0,1,2,\ldots\]</p>

</article></slide><slide class=""><hgroup><h2>Función de distribución geométrica</h2></hgroup><article  id="función-de-distribución-geométrica-2">

<p>En general, tendremos que: \[
F_X(x)=P(X\leq x)=
\left\{\begin{array}{ll} 
0, &amp; \mbox{ si } x&lt;0,\\
1- (1-p),  &amp; \mbox{ si } k=0\leq x &lt;1,\\
1- (1-p)^2, &amp; \mbox{ si } k=1\leq x &lt;2,\\
1- (1-p)^3, &amp; \mbox{ si } k=2\leq x &lt;3,\\
1- (1-p)^{k+1}, &amp; \mbox{ si } \left\{ \begin{array}{l}k\leq x&lt; k+1,\\\mbox{para } k=0,1,2,\ldots\end{array}
    \right.\end{array}\right.
\]</p>

</article></slide><slide class=""><hgroup><h2>Función de distribución geométrica</h2></hgroup><article  id="función-de-distribución-geométrica-3">

<p>De forma más compacta, tendremos que \[
F_X(x)=P(X\leq x)=
\left\{\begin{array}{ll} 
0, &amp; \mbox{ si } x&lt;0,\\
1- (1-p)^{k+1}, &amp; \mbox{ si } \left\{ \begin{array}{l}k\leq x&lt; k+1,\\\mbox{para } k=0,1,2,\ldots\end{array}
    \right.\end{array}
    \right.
\]</p>

<p>Notemos que el límite de la función de distribución es: \[
\displaystyle\lim_{k\to +\infty } F_X(k)=\lim_{k\to +\infty } 1-(1-p)^{k+1}=
1,
\] ya que \(0&lt;1-p&lt;1\).</p>

</article></slide><slide class=""><hgroup><h2>Sumas derivadas series geométricas</h2></hgroup><article  id="sumas-derivadas-series-geométricas">

<p>Recordemos del tema de variables aleatorias que</p>

<p><l class="prop">Propiedades</l></p>

<ul>
<li>Si \(|r|&lt;1\) también son convergentes las derivadas, respecto de \(r\), de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que \[
\begin{eqnarray*}
\left(\sum_{k=0}^{+\infty} r^k\right)&#39;&amp;= &amp; \sum_{k=1}^{+\infty}k\cdot
r^{k-1} &amp;=&amp; \left(\frac1{1-r}\right)&#39;=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{&#39;&#39;}&amp;=&amp; \sum_{k=2}^{+\infty}k \cdot(k-1)\cdot
r^{k-2}&amp;=&amp;\left(\frac1{1-r}\right)^{&#39;&#39;}=\frac2{(1-r)^3}
\end{eqnarray*}
\]</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Esperanza de una v.a. \(Ge(p)\)</h2></hgroup><article  id="esperanza-de-una-v.a.-gep">

<p>Recordemos que \(P(X=x)=(1-p)^x\cdot p\) si \(x=0,1,2,\ldots\) y aplicado la fórmula anterior con \(r=1-p\)</p>

<p>\[
\begin{eqnarray*}
E(X)&amp;=&amp;\sum_{x=0}^{+\infty} x\cdot P_x(x)=\sum_{x=0}^{+\infty} x\cdot (1-p)^x\cdot p\\
&amp;=&amp; p\cdot (1-p) \cdot \sum_{x=1}^{+\infty} x\cdot (1-p)^{x-1}\\
&amp;=&amp; p\cdot (1-p)\cdot \frac{1}{(1-(1-p))^2}=p\cdot (1-p)\cdot \frac{1}{p^2}=\frac{1-p}{p}
\end{eqnarray*}
\]</p>

</article></slide><slide class=""><hgroup><h2>Valor \(E(X^2)\) de una v.a. \(Ge(p)\)</h2></hgroup><article  id="valor-ex2-de-una-v.a.-gep">

<p>\[
\begin{eqnarray*}
E(X^2)&amp;=&amp;\sum_{x=0}^{+\infty} x^2\cdot P_X(x)=\sum_{x=1}^{+\infty} x^2\cdot (1-p)^x\cdot p\\
&amp;=&amp; 
\sum_{x=1}^{+\infty} (x\cdot (x-1)+x)\cdot (1-p)^{x}\cdot p\\
&amp;=&amp;
\sum_{x=1}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x}\cdot p+\sum_{x=1}^{+\infty} x \cdot (1-p)^{x}\cdot p\\
&amp;=&amp;
(1-p)^{2}\cdot p\cdot \sum_{x=2}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x-2}\\ 
&amp;  +&amp;   (1-p)\cdot p\sum_{x=1}^{+\infty} x \cdot (1-p)^{x-1} = \ldots
\end{eqnarray*}.
\]</p>

</article></slide><slide class=""><hgroup><h2>Valor \(E(X^2)\) de una v.a. \(Ge(p)\)</h2></hgroup><article  id="valor-ex2-de-una-v.a.-gep-1">

<p>\[
\begin{eqnarray*}
E(X^2)&amp;=&amp;\ldots\\
&amp;=&amp;
(1-p)^{2}\cdot p\cdot \sum_{x=2}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x-2}\\ 
&amp;  +&amp;   (1-p)\cdot p\sum_{x=1}^{+\infty} x \cdot (1-p)^{x-1}\\
&amp;=&amp;
p\cdot (1-p)^2 \frac{2}{(1-(1-p))^3}+  (1-p)\cdot p \frac{1}{(1-(1-p))^2}\\
&amp;=&amp;
p\cdot (1-p)^2 \frac{2}{p^3}+  (1-p)\cdot p \frac{1}{p^2}\\
&amp;=&amp;\frac{2\cdot (1-p)^2}{p^2}+\frac{1-p}{p}.
\end{eqnarray*}
\]</p>

</article></slide><slide class=""><hgroup><h2>Varianza de una v.a. \(Ge(p)\)</h2></hgroup><article  id="varianza-de-una-v.a.-gep">

<p>\[
\begin{eqnarray*}
Var(X)&amp;=&amp;E(X^2)-E(X)^2=\frac{2\cdot (1-p)^2}{p^2}+\frac{1-p}{p}-\left(\frac{1-p}{p}\right)^2\\
&amp;=&amp;
\frac{2\cdot (1-p)^2+p\cdot(1-p)-(1-p)^2}{p^2}=\frac{(1-p)^2+p\cdot(1-p)}{p^2}\\
&amp;=&amp;
\frac{1-2\cdot p + p^2+p-p^2}{p^2}\\
&amp;=&amp; \frac{1-p}{p^2}.
\end{eqnarray*}
\] Y su desviación típica será</p>

<p>\[\sqrt{Var(X)}=\sqrt{\frac{1-p}{p^2}}.\]</p>

</article></slide><slide class=""><hgroup><h2>Resumen \(Ge(p)\) empezando en 0</h2></hgroup><article  id="resumen-gep-empezando-en-0">

<table class = 'rmdtable'>
<col width="53.846154%" />
<col width="46.153846%" />
<tr class="header">
<th align="right">\(X=\) Geométrica (empieza en \(0\))</th>
<th align="left">número de fracasos para conseguir el primer éxito</th>
</tr>
<tr class="odd">
<td align="right">\(D_X=\)</td>
<td align="left">\(\{0,1,\ldots n,\ldots\}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(x)=P(X=x)=\)</td>
<td align="left">\(\left\{\begin{array}{ll}(1-p)^{x}\cdot p &amp; \mbox{ si } x=0,1,2,\ldots \\0 &amp; \mbox{ en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq X)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} 0 &amp; \mbox{ si } x&lt;0\\  1- (1-p)^{k+1} &amp; \mbox{ si } \left\{ \begin{array}{l}k\leq x&lt; k+1\\\mbox{para } k=0,1,2,\ldots\end{array}  \right.\end{array}\right.\)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=\frac{1-p}{p}\)</td>
<td align="left">\(Var(X)=\frac{1-p}{p^2}\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>La variable geométrica que cuenta los intentos para obtener el primer éxito.</h2></hgroup><article  id="la-variable-geométrica-que-cuenta-los-intentos-para-obtener-el-primer-éxito.">

<ul>
<li>Supongamos que sólo estamos interesados en el <strong>número de intentos</strong> para obtener el primer éxito.</li>
<li>Si definimos \(Y\)= número de intentos para obtener el primer éxito. Entonces \(Y=X+1\) donde \(X\equiv Ge(p)\).</li>
<li>Su dominio es \(D_Y=\{1,2,\ldots\}\)</li>
<li>La media se incrementa en un intento debido al éxito \(E(Y)=E(X+1)=E(X)+1=\frac{1-p}{p}+1=\frac1{p}\).</li>
<li>La varianza es la misma \(Var(Y)=Var(X+1)=Var(X)=\frac{1-p}{p^2}\).</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Resumen \(Ge(p)\) comenzando en \(1\).</h2></hgroup><article  id="resumen-gep-comenzando-en-1.">

<table class = 'rmdtable'>
<col width="53.846154%" />
<col width="46.153846%" />
<tr class="header">
<th align="right">\(Y\) geométrica (que cuenta el éxito empieza en 1)</th>
<th align="left">número de INTENTOS para OBTENER el primer éxito</th>
</tr>
<tr class="odd">
<td align="right">\(D_Y=\)</td>
<td align="left">\(\{1,2,\ldots n,\ldots\}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_Y(y)=P(Y=y)=\)</td>
<td align="left">\(\left\{\begin{array}{ll}(1-p)^{y-1}\cdot p &amp; \mbox{ si } y=1,2,3,\ldots\\ 0 &amp; \mbox{ en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_Y(y)=P(Y\leq y)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} 0 &amp; \mbox{ si } y&lt;1\\ 1- (1-p)^{k} &amp; \mbox{ si } \left\{ \begin{array}{l}k\leq y&lt; k+1\\\mbox{para } k=1,2,3,\dots \end{array} \right.\end{array}\right.\)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=\frac1{p}\)</td>
<td align="left">\(Var(X)=\frac{1-p}{p^2}\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Propiedad de la falta de memoria</h2></hgroup><article  id="propiedad-de-la-falta-de-memoria">

<p><l class="prop"> Propiedad de la falta de memoria </l></p>

<p>Sea \(X\) una v.a. discreta con dominio \(D_X=\{0,1,2,\ldots\}\), con \(P(X=0)=p\).</p>

<p>Entonces \(X\) sigue una ley \(Ge(p)\) si, y sólo si, \[
P\left(X&gt; k+j\big| X\geq j\right)=P(X&gt; k)
\] para todo \(k,j=0,1,2,3\ldots\).</p>

</article></slide><slide class=""><hgroup><h2>Propiedad de la falta de memoria</h2></hgroup><article  id="propiedad-de-la-falta-de-memoria-1">

<div class="dem">
<p><strong>Demostración</strong></p>

<p>Si \(X\) es geométrica entonces el lado derecho de la igualdad es</p>

<p>\[
P(X&gt;k)=1-P(X\leq k)=1-\left(1-(1-p)^{k+1}\right)=(1-p)^{k+1},
\] y el lado de izquierdo es \[
\begin{eqnarray*} 
P\left(X&gt; k+j\big| X\geq j\right)&amp;=&amp;\frac{P\left(\{X&gt; k+j\}\cap \{X\geq j\} \right)}{P\left(X\geq j\right)}=
\frac{P\left(X&gt;k+j \right)}{P\left(X\geq j \right)} = \frac{1-P(X\leq k+j)}{1-P(X\leq j-1)}\\
&amp;=&amp;  \frac{1-(1-(1-p)^{k+j+1})}{1-(1-(1-p)^{j-1+1})} =\frac{(1-p)^{k+j+1}}{(1-p)^{j}} = (1-p)^{k+1},
\end{eqnarray*}
\] lo que demuestra la igualdad.</p></div>

</article></slide><slide class=""><hgroup><h2>Propiedad de la falta de memoria</h2></hgroup><article  id="propiedad-de-la-falta-de-memoria-2">

<div class="dem">
<p>Para demostrar el recíproco, tomemos \(j=1\) y \(k\geq 0\). Entonces, por la propiedad de la pérdida de memoria: \[
P\left(X&gt; k+1\big| X\geq 1\right)=P(X&gt; k)
\] Como \(P(X=0)=p\), tenemos que \(P(X \geq 1 )=1-P(X&lt;1)=1-P(X=0)=1-p\).</p>

<p>Combinado las igualdades, tenemos que:</p>

<p>\[
P\left(X&gt; k+1\big| X\geq 1\right)=\frac{P(X&gt;k+1, X\geq 1)}{P(X\geq 1)}=\frac{P(X&gt;k+1)}{P(X\geq 1)}=P(X&gt;k).
\] Así podemos poner que</p>

<p>\[
\begin{eqnarray*}
P(X&gt;k+1)&amp;=&amp;P(X\geq 1)\cdot P(X&gt;k)=\left(1-P(X&lt;1)\right)\cdot P(X&gt;k)\\
&amp;=&amp;\left(1-P(X=0)\right)\cdot P(X&gt;k)=(1-p)\cdot P(X&gt;k).
\end{eqnarray*}
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Propiedad de la falta de memoria</h2></hgroup><article  id="propiedad-de-la-falta-de-memoria-3">

<div class="dem">
<p>Es decir en general tenemos que</p>

<p>\[
P(X&gt;k+1)=(1-p)\cdot P(X&gt;k)
\] Del mismo modo para \(j=2\)</p>

<p>\[
P(X&gt;k+2)=(1-p)\cdot P(X&gt;k+1)
\]</p>

<p>Restando la primera igualdad de la última obtenemos.</p>

<p>\[
P(X&gt;k+1)-P(X&gt;k+2)=(1-p)\cdot P(X&gt;k)-(1-p)\cdot P(X&gt;k+1)
\]</p>

<p>de donde operando en cada lado de la igualdad obtenemos la recurrencia</p>

<p>\[
[1-P(X\leq k+1)]-[1-P(X\leq k+2)]=(1-p)\cdot [P(X&gt;k)-P(X&gt;k+1)]
\]</p>

<p>Ahora operando \[
P(X\leq k+2)-P(X\leq k+1)=(1-p)\cdot[1-P(X\leq k)-\left(1-P(X\leq k+1)\right)]
\] \[
P(X=k+2)=(1-p)\cdot[P(X\leq k+1)-P(X\leq k)]
\] \[
P(X=k+2)=(1-p)\cdot P(X=k+1)
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Propiedad de la falta de memoria</h2></hgroup><article  id="propiedad-de-la-falta-de-memoria-4">

<div class="dem">
<p>De forma similar obtenemos</p>

<p>\[
P(X=k+1)=(1-p)\cdot P(X=k)
\] Utilizando la recurrencia anterior, podemos calcular todas las probabilidades \(P(X=k)\) a partir de la \(P(X=0)=p\):</p>

<p>\[
\begin{array}{rl}
P(X=0)&amp;= p,\\
P(X=1)&amp;=P(X=0+1)= (1-p)\cdot P(X=0) =(1-p)\cdot  p,\\
P(X=2)&amp;=P(X=1+1)= (1-p)\cdot P(X=1)=(1-p)\cdot (1-p)\cdot p=(1-p)^2\cdot p,\\
 \vdots&amp; \vdots \\
P(X=k)&amp;=P(X=(k-1)+1)= (1-p)\cdot P(X=k-1)=(1-p)\cdot (1-p)^{k-1}\cdot p=(1-p)^{k}\cdot p,
\end{array}
\] lo que demuestra el recíproco, es decir, que \(X\) es \(Geom(p)\).</p></div>

</article></slide><slide class=""><hgroup><h2>Falta de memoria</h2></hgroup><article  id="falta-de-memoria">

<p><l class="observ"> Observación: Interpretación de la propiedad</l></p>

<p>La propiedad de la falta de memoria \[
P(X&gt; k+j\big|X \geq j)=P(X &gt; k),
\]<br/>significa que, aunque <strong>ya llevemos al menos \(j\) fracasos</strong>, la probabilidad de <strong>que fracasemos \(k\) veces más</strong> no disminuye, es la misma que era cuando empezamos el experimento.</p>

<p>A este efecto se le suele etiquetar con la frase <strong>el experimento carece de memoria</strong> o es un <strong>experimento sin memoria</strong> (<em>Memoryless Property</em>).</p>

</article></slide><slide class=""><hgroup><h2>Ejemplo falta de memoria</h2></hgroup><article  id="ejemplo-falta-de-memoria">

<p>Un ejemplo muy sencillo nos aclarará el alcance de esta propiedad</p>

<div class="exercise">
<p><strong>Ejercicio: la llave que abre la puerta</strong></p>

<p>Tenemos un llavero con 10 llaves, solo una de ellas abre una puerta. Cada vez que probamos una llave y falla olvidamos que llave hemos probado. ¿Cuál es la probabilidad de que si ya lo hemos intentado 5 veces necesitemos más de 4 intentos adicionales para abrir la puerta?</p></div>

<div class="example-sol">
<p>Tomemos \(k=4,j=5\), aplicando la propiedad de la falta de memoria</p>

<p>\[
P(X&gt; 4+5/X \geq 5)=P(X &gt; 4)
\]</p>

<p>Después de 5 fracasos no estamos &ldquo;más cerca&rdquo; de abrir la puerta. La propiedad de la falta de memoria nos dice que en <strong>después de cada intento es como si empezásemos de nuevo a abrir la puerta</strong>. Tras 5 fracasos la probabilidad de que fallemos más de 4 veces más es la misma que cuando lo intentamos la primera vez.</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo falta de memoria</h2></hgroup><article  id="ejemplo-falta-de-memoria-1">

<div class="example-sol">
<p>¿Cuál es el número esperado de fracasos hasta abrir la puerta?</p>

<p>\[
E(X)=\frac{1-p}{p}=\frac{1-\frac{1}{10}}{\frac{1}{10}}=\frac{\frac{9}{10}}{\frac{1}{10}}=9.
\]</p>

<p>La varianza es</p>

<p>\[
Var(X)=\frac{1-p}{p^2}=\frac{1-\frac{1}{10}}{\left(\frac{1}{10}\right)^2}=\frac{\frac{9}{10}}{\frac{1}{100}}=
90.
\]</p>

<p>La desviación típica es \(\sqrt{90}=9.486833.\)</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo: El clásico del fútbol</h2></hgroup><article  id="ejemplo-el-clásico-del-fútbol">

<div class="exercise">
<p><strong>Ejemplo: partidos hasta que el Barça gana al Madrid</strong></p>

<p>Los partidos Real Madrid vs FC Barcelona de <strong>la liga</strong> española se suelen denominar <strong>El Clásico</strong>, sean en el Bernabeu (estadio del Real Madrid) o en el Camp Nou (estadio del Barça)</p>

<p>Sea \(X\) la variable que cuenta el número de veces consecutivas que en un partido de fútbol de la liga el Barça no gana al Madrid sea en el Camp Nou o el Bernabeu.</p>

<p>Nuestra amiga Aina es muy culé (hincha del Barça) y quiere averiguar cuántos partidos consecutivos de <strong>El Clásico</strong> tiene que ver hasta ver ganar al Barça por primera vez.</p>

<p>Le interesa estimar cuánto le va a costar este capricho. Tendrá que comprar las entradas y pagar los viajes de Barcelona a Madrid.</p>

<p>En <a href='https://es.wikipedia.org/wiki/El_Cl%C3%A1sico' title=''>datos historicos de <strong>El clásico</strong> en la wikipedia</a> están los datos hasta el 3 de marzo de 2019: se han jugado en total 178 <strong>Clásicos</strong> donde el Real Madrid ganó en 72 ocasiones, el Barça, en 72 y empataron 34 veces.</p>

<p>Nos hacemos las siguientes preguntas:</p>

<ul>
<li>Si Aina solo tiene dinero para ir a ver 3 partidos, ¿cuál es la probabilidad de no ver ganar al Barça en al menos tres partidos consecutivos?</li>
<li>¿Cuántos partidos se tienen que jugar de media para ver ganar al Barça por primera vez?</li>
</ul></div>

</article></slide><slide class=""><hgroup><h2>Variable geométrica: El clásico</h2></hgroup><article  id="variable-geométrica-el-clásico">

<div class="example-sol">
<p>Con los datos anteriores, podemos estimar que la probabilidad de que el Barça gane un clásico cualquiera es:</p>

<p>\[P(\mbox{Barça})=\frac{72}{178}=0.4045.\]</p>

<p>Por tanto, podemos modelar la variable \(X\), que cuenta el número de veces consecutivas que en un partido de fútbol de la liga el Barça no gana al Madrid, con una ley geométrica empezando en cero con probabilidad de éxito \(p=P(\mbox{Barça})=\frac{72}{178}\),</p>

<p>\[X=Ge\left(p=\frac{72}{178}=0.4045\right)\]</p>

<p>Así que lo que nos pregunta Aina es la siguiente probabilidad</p>

<p>\[P(X\geq 3)=1-P(X\leq 2)=1-\left(1-\frac{72}{178}\right)^{2+1}=0.7888.\]</p>

<p>Así que Aina tiene una probabilidad del \(78.88\%\) de no ver ganar al Barça en al menos 3 partidos antes de ver uno en el sí que gane.</p></div>

</article></slide><slide class=""><hgroup><h2>Variable geométrica: El clásico</h2></hgroup><article  id="variable-geométrica-el-clásico-1">

<div class="example-sol">
<p>Para responder a la segunda pregunta, usando que la distribución de \(X\) es:</p>

<p>\[X=Ge\left(p=\frac{72}{178}=0.4045\right)\]</p>

<p>entonces</p>

<p>\[E(X)=\frac{1-p}{p}=\frac{1-0.4045}{0.4045}=1.4722\]</p>

<p>y</p>

<p>\[Var(X)=\frac{1-p}{p^2}=\frac{1-0.4045}{0.4045^2}=3.6397\]</p>

<p>La desviación típica es \[\sqrt{3.6397}=1.9078.\]</p></div>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r">

<p>Veamos los cálculos básicos con R para la distribución geométrica \(Ge(p=0.25)\). R implementa la geométrica que cuenta el número de fracasos.</p>

<p>\(P(X=0)=(1-0.25)^0\cdot 0.25^1=0.25\)</p>

<pre class = 'prettyprint lang-r'>dgeom(0,prob=0.25)</pre>

<pre >## [1] 0.25</pre>

<p>\(P(X\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25\)</p>

<pre class = 'prettyprint lang-r'>pgeom(0,prob=0.25)</pre>

<pre >## [1] 0.25</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-1">

<p>\(P(X\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=0.7626953.\)</p>

<pre class = 'prettyprint lang-r'>pgeom(4,prob=0.25)</pre>

<pre >## [1] 0.7626953</pre>

<p>Una muestra aleatoria de tamaño 25 de una \(Ge(0.25)\)</p>

<pre class = 'prettyprint lang-r'>rgeom(n=25,prob=0.25)</pre>

<pre >##  [1]  5  4  1  6 10  0  0 10  7  0  6  2  1  3  0  2  5  0  0  5  5  3  3  2  2</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos con R el código</h2></hgroup><article  id="gráficos-con-r-el-código">

<pre class = 'prettyprint lang-r'>par(mfrow=c(1,2))
x=c(0:10)
plot(x=x,y=dgeom(x,prob=0.25),
  ylim=c(0,1),xlim=c(-1,11),xlab=&quot;x&quot;,
  main=&quot;Función de probabilidad\n Ge(p=0.25)&quot;)
lines(x=rep(0:10,each=2),y=aux, type = &quot;h&quot;, lty = 2,col=&quot;blue&quot;)
aux0=dgeom(c(0:10),prob=0.25)
ceros=rep(0,21)
ceros
aux=ceros
aux[2*(c(1:11))]&lt;-aux0
curve(pgeom(x,prob=0.25),
  xlim=c(-1,10),col=&quot;blue&quot;,
  main=&quot;Función de distribución\n Ge(p=0.25)&quot;)
par(mfrow=c(1,1))</pre>

</article></slide><slide class=""><hgroup><h2>Los gráficos con R</h2></hgroup><article  id="los-gráficos-con-r">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/graficos22-1.png" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficas interactivas geométrica</h2></hgroup><article  id="gráficas-interactivas-geométrica">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

<p>O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a> ```</p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python">

<p>Veamos los cálculos básicos con python para la distribución geométrica \(Ge(p=0.25)\). scipy.stats implementa la distribución geométrica que cuenta el número intentos así que empieza en 1</p>

<p>Cargamos la función de la librería</p>

<pre class = 'prettyprint lang-python'>from scipy.stats import geom</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/geom1-1.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-1">

<p>La función de probabilidad es <code>geom.pmf(x,p,loc=0)=geom.pmf(x,p)</code> es un geométrica que cuenta el número de intentos para obtener el primer éxito el valor por defecto del último parámetro es <code>loc=0</code>.</p>

<p>Si queremos la que cuenta el número de fracasos para obtener el primer éxito (la geométrica que empieza en 0) tenemos que usar <code>geom.pmf(x,p,loc=-1)</code>.</p>

<p>Es decir <code>geom.pmf(x,p,loc=-1)=geom.pmf(x-1,p,loc=0)</code></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-2">

<p>Veamos pues los cálculos para la \(Ge(p)\) que empieza en \(0\).</p>

<p>\(P(X=0)=(1-0.25)^0\cdot 0.25^1=0.25\)</p>

<pre class = 'prettyprint lang-python'>geom.pmf(0,p=0.25,loc=-1)</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_geom_funciones1-3.png" width="480" /></p>

<p>\(P(X\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25\)</p>

<pre class = 'prettyprint lang-python'>geom.cdf(0,p=0.25,loc=-1)</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_geom_funciones2-5.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-3">

<p>\(P(X\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=0.7626953.\)</p>

<pre class = 'prettyprint lang-python'>geom.cdf(4,p=0.25,loc=-1)</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_geom_funciones3-7.png" width="480" /></p>

<p>Una muestra aleatoria de tamaño 25 de una \(Ge(0.25)\)</p>

<pre class = 'prettyprint lang-python'>geom.rvs(p=0.25, size=20, loc=-1)</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_random_binom-9.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-4">

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Qué probabilidades son las que calcula el siguiente código y qué tipo de variables geométricas son?</p></div>

<pre class = 'prettyprint lang-python'>geom.cdf(range(5),p=0.3,loc=0)
geom.cdf(range(5),p=0.3,loc=-1)</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-21-11.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python esperanza y varianza</h2></hgroup><article  id="cálculos-con-python-esperanza-y-varianza">

<p>Con python también podemos calcular directamente algunos parámetros asociado a una función de distribución predefinida</p>

<pre class = 'prettyprint lang-python'>geom.stats(p=0.25, loc=0, moments=&#39;mv&#39;)
geom.stats(p=0.25, loc=-1, moments=&#39;mv&#39;)</pre>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_mean_var_stats-13.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python esperanza y varianza</h2></hgroup><article  id="cálculos-con-python-esperanza-y-varianza-1">

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Comprobad que las medias y las varianzas calculadas en el código anterior, corresponden a una \(Ge(p=0.3)\) empezando en \(1\) y a una \(Ge(p=0.3)\) empezando en \(0\).</p>

<p>¿Son las varianzas siempre iguales?</p></div>

</article></slide><slide class=""><hgroup><h2>Gráficos con python</h2></hgroup><article  id="gráficos-con-python">

<pre class = 'prettyprint lang-python'>p = 0.25
x = np.arange(geom.ppf(0.01, p),geom.ppf(0.99, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, geom.pmf(x, p), &#39;bo&#39;, ms=5, label=&#39;geom pmf&#39;)
ax.vlines(x, 0, geom.pmf(x, p), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, geom.cdf(x, p), &#39;bo&#39;, ms=5, label=&#39;geom pmf&#39;)
ax.vlines(x, 0, geom.cdf(x, p), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle(&#39;Distribucion Geometrica&#39;)
plt.show()</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos con python</h2></hgroup><article  id="gráficos-con-python-1">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-22-15.png" width="480" /></p>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribución binomial negativa</h2></hgroup><article  id="distribución-binomial-negativa">

</article></slide><slide class=""><hgroup><h2>El problema de la puerta con dos cerraduras</h2></hgroup><article  id="el-problema-de-la-puerta-con-dos-cerraduras">

<p>Supongamos que disponemos de 10 llaves distintas y tenemos que abrir una puerta con <strong>dos cerraduras</strong>.</p>

<p>Comenzamos por la primera cerradura, de tal forma que cada vez olvidamos qué llave hemos probado.</p>

<p>Una vez abierta la primera cerradura probamos de igual forma con la segunda hasta que también la abrimos.</p>

<p>Sea \(X=\) la v.a. que cuenta el número de fracasos hasta abrir la puerta.</p>

<p>Acertar una llave de la puerta es un experimento Bernoulli con probabilidad de éxito \(p=0.1\). Lo repetiremos hasta obtener 2 éxitos.</p>

</article></slide><slide class=""><hgroup><h2>Distribución binomial negativa</h2></hgroup><article  id="distribución-binomial-negativa-1">

<p>En general tendremos un experimento de Bernoulli con probabilidad de éxito \(0&lt;p&lt;1\) tal que:</p>

<ul>
<li>Repetimos el experimento hasta obtener el \(n\)-ésimo éxito ¡¡abrir la maldita puerta!!.</li>
<li>Sea \(X\) la v.a. que cuenta el número fallos hasta abrir la puerta, es decir, hasta conseguir el n-ésimo éxito. Notemos que no contamos los éxitos, solo contamos los fracasos</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Distribución binomial negativa</h2></hgroup><article  id="distribución-binomial-negativa-2">

<p>Si representamos como es habitual un suceso como una cadena de F’s y E’s, para \(n=2\), algunos sucesos elementales serán: \[\small{\{EE,FEE,EFE, FFEE,FEFE,EFFE,FFFEE,FFEFE,FEFFE,EFFFE\}.}\]</p>

<p>Calculemos algunas probabilidades para \(n=2\): \[
\small{
\begin{array}{rl}
P(X=0) &amp; =P(\{EE\})=p^2, \\
P(X=1) &amp; =P(\{FEE,EFE\})=2\cdot (1-p)\cdot p^2, \\
P(X=2) &amp; =P(\{FFEE,FEFE,EFFE\})=3\cdot (1-p)^2\cdot p^2, \\
P(X=3) &amp; =P(\{FFFEE,FFEFE,FEFFE,EFFFE\})=4\cdot (1-p)^3\cdot p^2.
\end{array}
}
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución binomial negativa</h2></hgroup><article  id="distribución-binomial-negativa-3">

<p>En general su función de probabilidad es</p>

<p>\[
P_{X}(k)=P(X=k)=\left\{\begin{array}{ll}
     {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n &amp; \mbox{si } k=0,1,\ldots\\
     0 &amp; \mbox{en otro caso}\end{array}\right.
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución binomial negativa</h2></hgroup><article  id="distribución-binomial-negativa-4">

<p>Una v.a. con este tipo de distribución recibe el nombre de <strong>binomial negativa</strong> y la denotaremos por \(BN(n,p)\).</p>

<p>Notemos que \(BN(1,p)=Ge(p)\).</p>

</article></slide><slide class=""><hgroup><h2>Distribución binomial negativa</h2></hgroup><article  id="distribución-binomial-negativa-5">

<div class="dem">
<p><strong>Demostración</strong></p>

<p>Justifiquemos el resultado. Sea \(X\) una \(BN(n,p)\) y sea \(k=0,1,2,\ldots\).</p>

<p>\[P(X=k)=P(\mbox{Todas las cadenas de E&#39;s y F&#39; con $k$ F, con $n$ E y acabadas en E})\]</p>

<p>\[
\overbrace{\underbrace{\overbrace{EFFF\ldots EEF}^{n-1 \quad \mbox{Éxitos}.}}}_{k \quad\mbox{Fracasos}}^{k+n-1\mbox{ posiciones}}E
\]</p>

<p>De estas cadenas hay tantas como maneras de elegir de entre las \(k+n-1\) primeras posiciones \(n-1\) para colocar los éxitos. Esta cantidad es el número binomial \[{k+n-1\choose n-1}.\]</p></div>

</article></slide><slide class=""><hgroup><h2>Números binomiales negativos</h2></hgroup><article  id="números-binomiales-negativos">

<p><l class="definition"> Números binomiales negativos</l></p>

<p>Dados dos enteros positivos \(n\) y \(k\) se define el número binomial negativo como</p>

<p>\[\binom{-n}{k}=\frac{(-n)(-n-1)\cdots (-n-k+1)}{k!}.\]</p>

<p>Los números binomiales negativos generalizan la fórmula de Newton para exponentes negativos: \[
(t+1)^{-n}=\sum_{k=0}^{+\infty}\left(\begin{array}{c} -n
\\ k\end{array}\right) t^{k}
\]</p>

</article></slide><slide class=""><hgroup><h2>Números binomiales negativos</h2></hgroup><article  id="números-binomiales-negativos-1">

<p><code>R</code> usa la función <code>choose</code> para calcular números binomiales, sean negativos o no. Veámoslo con un ejemplo:</p>

<p>\[
\begin{array}{rl}
{-6\choose 4}&amp;=\frac{-6\cdot (-6-1)\cdot \cdot (-6-2)\cdot (-6-3) }{4!}\\
&amp;=  \frac{-6\cdot(-7)\cdot (-8)\cdot (-9)}{24}\\
&amp;= \frac{3024}{24}=126.
\end{array}
\]</p>

<p>Si realizamos el cálculo con <code>R</code> obtenemos el mismo resultado:</p>

<pre class = 'prettyprint lang-r'>choose(-6,4)</pre>

<pre >## [1] 126</pre>

</article></slide><slide class=""><hgroup><h2>Esperanza de una \(BN(n,p)\)</h2></hgroup><article  id="esperanza-de-una-bnnp">

<p>Su <strong>esperanza es</strong></p>

<p>\[E(X)=\sum_{k=0}^{+\infty} k\cdot {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n=n\cdot\frac{1-p}{p}.\]</p>

<p>La <strong>esperanza de \(X^2\) es</strong></p>

<p>\[E(X^2)=\sum_{k=0}^{+\infty} k^2\cdot {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n=n\cdot\frac{1-p}{p^2}+\left(n\cdot \frac{1-p}{p}\right)^2.\]</p>

</article></slide><slide class=""><hgroup><h2>Varianza de una \(BN(n,p)\)</h2></hgroup><article  id="varianza-de-una-bnnp">

<p>Por último la <strong>varianza es</strong></p>

<p>\[
Var(X)=E(X^2)-E(X)^2=
\]</p>

<p>\[=n\cdot \frac{1-p}{p^2}+\left(n\cdot \frac{1-p}{p}\right)^2-\left(n\cdot \frac{1-p}{p}\right)^2=
n\cdot \frac{1-p}{p^2}.\]</p>

<p>y por tanto la desviación típica es</p>

<p>\[\sqrt{Var(X)} = \frac{\sqrt{n(1-p)}}{p}\]</p>

</article></slide><slide class=""><hgroup><h2>Resumen Binomial Negativa \(BN(n,p)\)</h2></hgroup><article  id="resumen-binomial-negativa-bnnp">

<table class = 'rmdtable'>
<col width="53.571429%" />
<col width="46.428571%" />
<tr class="header">
<th align="right">\(X\), \(BN(n,p)\)</th>
<th align="left">Número de fracasos antes de conseguir el \(n\)-ésimo éxito. Probabilidad de éxito \(p\)</th>
</tr>
<tr class="odd">
<td align="right">\(D_X=\)</td>
<td align="left">\(\{0,1,2,3\ldots\}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(k)=P(X=k)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n, &amp; \mbox{si } k=0,1,\ldots \\ 0, &amp; \mbox{en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq x)=\)</td>
<td align="left">\(\begin{array}{l}\left\{\begin{array}{ll} 0, &amp; \mbox{si } x&lt;0\\\displaystyle\sum_{i=0}^{k} P(X=i) &amp; \mbox{si }\left\{\begin{array}{l}k\leq x&lt; k+1,\\k=0,1,2,\ldots\end{array}\right.\end{array}\right. \\\mbox{Calcular la suma o utilizar funciones de `R` o python.} \end{array}\)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=n\cdot\frac{1-p}{p}\)</td>
<td align="left">\(Var(X)=n\cdot \frac{1-p}{p^2}\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Ejemplo puerta dos cerraduras \(BN(n=2,p=0.1)\).</h2></hgroup><article  id="ejemplo-puerta-dos-cerraduras-bnn2p0.1.">

<div class="exercise">
<p><strong>Ejercicio: Puerta con dos cerraduras</strong></p>

<p>Recordemos nuestra puerta con dos cerraduras que se abren secuencialmente. Tenemos un manojo de 10 llaves casi idénticas de manera que cada vez que probamos una llave olvidamos qué llave hemos usado.</p>

<p>Sea \(X\) la v.a que nos da el número de intentos fallidos hasta abrir abrir la puerta.</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n,p)\)</h2></hgroup><article  id="ejemplo-bnnp">

<div class="exercise">
<p>Estamos interesado en modelar este problema. La preguntas son:</p>

<ol>
<li>¿Cuál es la distribución de probabilidad de \(X\) la v.a que nos da el número fallos hasta abrir la puerta?</li>
<li>¿Cuál es la función de probabilidad y de distribución de \(X\)?</li>
<li>¿Cuál es la probabilidad de fallar exactamente 5 veces antes de abrir la puerta?</li>
<li>¿Cuál es la probabilidad de fallar más de 4?</li>
<li>¿Cuál es el número esperado de fallos? ¿Y su desviación típica?</li>
</ol></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo dos cerraduras \(BN(n=2,p=0.1)\).</h2></hgroup><article  id="ejemplo-dos-cerraduras-bnn2p0.1.">

<div class="example-sol">
<p><strong>Solución 1.</strong> ¿Cuál es la distribución de probabilidad de \(X\) la v.a que nos da el número fallos hasta abrir la puerta?</p>

<p>Bajo estados condiciones tenemos que la probabilidad de &ldquo;éxito&rdquo; de cada intento es \(p=\frac{1}{10}=0.1\). Como cada vez <em>olvidamos</em> qué llave hemos probado, cada intento será independiente del anterior.</p>

<p>Así que la variable \(X\) que queremos modelar cuenta el número fallos de repeticiones sucesivas e independientes de un experimento \(Ber(p=0.1)\) hasta conseguir 2 éxitos en un experimento.</p>

<p>Por lo tanto podemos asegurar que \(X\) sigue un distribución \(BN(n=2,p=0.1).\)</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1">

<div class="example-sol">
<p><strong>Solución 2.</strong> ¿Cuál es la función de probabilidad y de distribución del \(X\)?</p>

<p>En general la función de probabilidad de una \(BN(n,p)\) es</p>

<p>\[
P_X(k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n &amp; \mbox{si }  k=0,1,\ldots \\ 0 &amp; \mbox{en otro caso.}\end{array}\right.
\]</p>

<p>Si aplicamos la expresión anterior para \(n=2\) y \(p=0.1\), obtenemos: \[
P_X(k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+2-1\choose 2-1} \cdot 0.9^{k}\cdot 0.1^2 &amp; \mbox{si }  k=0,1,2,\ldots \\ 0 &amp; \mbox{en otro caso.}\end{array}\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1-1">

<div class="example-sol">
<p>Simplificando</p>

<p>\[
P_X(X=k)=P(X=k)=
\left\{
\begin{array}{cc} 
0.01\cdot (k+1)\cdot 0.9^{k}, &amp; \mbox{si }  k=0,1,2,\ldots \\ 0 &amp; \mbox{en otro caso.}\end{array}\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1-2">

<div class="example-sol">
<p>La función de distribución en general es</p>

<p>\[
F_X(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0 &amp; \mbox{si } x&lt;0 \\
\displaystyle\sum_{i=0}^{k }{i+n-1\choose n-1} \cdot (1-p)^{i+n-1}\cdot p^n 
&amp; \mbox{si }\left\{\begin{array}{l} k\leq x&lt; k+1\\k=0,1,2,\ldots\end{array}\right. 
\end{array}
\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1-3">

<div class="example-sol">
<p>Simplificando para \(n=2\), \(p=0.1\).</p>

<p>\[
F_X(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0, &amp; \mbox{si } x&lt;0, \\
\displaystyle\sum_{i=0}^{k }0.01\cdot (i+1) \cdot 0.9^{i+1},
&amp; \mbox{si }\left\{\begin{array}{l} k\leq x&lt; k+1,\\k=0,1,2,\ldots\end{array}\right. 
\end{array}
\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1-4">

<div class="example-sol">
<p><strong>Solución 3.</strong> ¿Cuál es la probabilidad de fallar exactamente 5 veces antes de abrir la puerta?</p>

<p>\[
P(X=5)= 0.01\cdot (5+1) \cdot 0.9^{5}= 0.06 \cdot 0.9^{5}= 0.0354294.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1-5">

<div class="example-sol">
<p><strong>Solución 4.</strong> ¿Cuál es la probabilidad de fallar más de 4?</p>

<p>Nos piden que<br/>\[
P(X&gt;4)=1-P(X\leq 4).
\]</p>

<p>Calculemos primero \(P(X\leq 4):\)</p>

<p>\[
\begin{array}{rl}
P(X\leq 4) &amp;=  \displaystyle\sum_{x=0}^{4} P(X=x)=P(X=0)+P(X=1)+P(X=2)+P(X=3)+P(X=4)\\
&amp;= 0.01\cdot (0+1) \cdot 0.9^{0}+0.01\cdot (1+1) \cdot 0.9^{1}+0.01\cdot (2+1) \cdot 0.9^{2} \\ &amp;\ \ 
+0.01\cdot (3+1) \cdot 0.9^{3} + 0.01\cdot (4+1) \cdot 0.9^{4} \\ &amp; =
0.01 +0.018+0.0243+0.02916+0.032805 = 0.114265.
\end{array}
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(n=2,p=0.1)\)</h2></hgroup><article  id="ejemplo-bnn2p0.1-6">

<div class="example-sol">
<p>Por lo tanto</p>

<p>\[
P(X&gt;4)=1-P(X\leq 4)=1-0.114265=
0.885735.
\]</p>

<p><strong>Solución 5.</strong> ¿Cuál es el número esperado de fallos? ¿Y su desviación típica?</p>

<p>Como \(X\) sigue una ley \(BN(n=2,p=0.1)\)</p>

<p>\[E(X)=n\cdot \frac{1-p}{p}=2\cdot \frac{1-0.1}{0.1}=18.\]</p>

<p>El número de fallos esperado es 18.</p>

<p>La varianza será: \[
Var(X)=n\cdot\frac{1-p}{p^2}=2 \cdot \frac{1-0.1}{0.1^2}=180.
\]</p>

<p>La varianza de \(X\) es 180 y su desviación típica \(\sqrt{180}=13.41641.\)</p></div>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-2">

<p>La función de <code>R</code> que calcula la función de probabilidad de la binomial negativa con sus parámetros básicos es:</p>

<pre >dnbinom(x, size, prob,...)`</pre>

<p>donde <code>size</code> (\(n\)) es el número de éxitos y <code>prob</code> (\(p\)), la probabilidad de éxito.</p>

<p>Así en el ejemplo de la puerta con dos cerraduras, \(X\) es una \(BN(n=size=2,p=prob=0.1)\). Por ejemplo, \(P(X=5)\) que hemos calculado en el ejemplo anterior, vale:</p>

<pre class = 'prettyprint lang-r'>dnbinom(5,size=2,p=0.1)</pre>

<pre >## [1] 0.0354294</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-3">

<p>De forma similar calculamos calculamos \(P(X\leq 4)\), \(P(X&gt;4)=1-P(X\leq 4)\) y \(P(X&gt;4)\).</p>

<pre class = 'prettyprint lang-r'>pnbinom(4,size=2,p=0.1)</pre>

<pre >## [1] 0.114265</pre>

<pre class = 'prettyprint lang-r'>1-pnbinom(4,size=2,p=0.1)</pre>

<pre >## [1] 0.885735</pre>

<pre class = 'prettyprint lang-r'>pnbinom(4,size=2,p=0.1,lower.tail=FALSE)</pre>

<pre >## [1] 0.885735</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-5">

<p>La función con python es <code>nbinom.pmf(k, n, p, loc)</code>. Hay que cargarla desde <code>scpi.stats</code></p>

<pre class = 'prettyprint lang-python'>from scipy.stats import nbinom</pre>

<p>Recordemos que de nuevo se cumple que</p>

<pre class = 'prettyprint lang-python'>nbinom.pmf(k, n, p, loc) = nbinom.pmf(k-loc, n, p)`</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos \(BN(n,p)\) con python</h2></hgroup><article  id="cálculos-bnnp-con-python">

<pre class = 'prettyprint lang-python'>nbinom.pmf(k=5,n=2,p=0.1)</pre>

<pre >## 0.03542940000000002</pre>

<pre class = 'prettyprint lang-python'>nbinom.pmf(k=5,n=2,p=0.1,loc=0)</pre>

<pre >## 0.03542940000000002</pre>

<pre class = 'prettyprint lang-python'>nbinom.cdf(k=4,n=2,p=0.1)</pre>

<pre >## 0.11426500000000003</pre>

<pre class = 'prettyprint lang-python'>1-nbinom.cdf(k=4,n=2,p=0.1)</pre>

<pre >## 0.8857349999999999</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos \(BN(n,p)\) con python</h2></hgroup><article  id="cálculos-bnnp-con-python-1">

<p>Generemos 100 observaciones aleatorias de una \(BN(n=2,0.1)\). Es decir serán las veces que hemos fallado hasta abrir la puerta 100 veces.</p>

<pre class = 'prettyprint lang-python'>nbinom.rvs(n=2, p=0.1, size=100)</pre>

<pre >## array([11, 16, 28, 19, 33,  8,  8, 35, 22, 45,  7,  7, 23,  7, 17, 24,  3,
##         5, 13, 14, 12, 13, 21, 12, 10, 33, 13,  2, 13,  7, 15, 19,  8, 11,
##        22, 50,  6, 34, 28, 18, 18,  1, 19,  3, 19, 21, 29, 17, 17, 11, 33,
##        12, 10,  3,  3, 37, 31,  5,  5,  8, 60, 16, 19, 10, 10,  3, 10,  8,
##        24, 11, 42, 10,  5,  9,  7,  0, 23, 22,  9, 30,  8, 49, 10, 21, 38,
##        13, 18, 11, 23, 19,  1, 50, 17, 29,  0, 23,  9,  9, 75,  8])</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos \(BN(n,p)\) con python</h2></hgroup><article  id="cálculos-bnnp-con-python-2">

<p>La <strong>esperanza</strong> y la <strong>varianza</strong>de una \(BN(n=2,0.1)\) valen:</p>

<pre class = 'prettyprint lang-python'>n, p=2,0.1
params = nbinom.stats(n,p,moments=&#39;mv&#39;)
print(&quot;E(X)={m}&quot;.format(m=params[0]))</pre>

<pre >## E(X)=18.0</pre>

<pre class = 'prettyprint lang-python'>print(&quot;Var(X)={v}&quot;.format(v=params[1]))</pre>

<pre >## Var(X)=180.0</pre>

</article></slide><slide class=""><hgroup><h2>Gráficas de la binomial negativa con R</h2></hgroup><article  id="gráficas-de-la-binomial-negativa-con-r">

<p>El siguiente código de R dibuja las función de probabilidad y la de distribución de una \(BN(n=2,p=0.1)\)</p>

<pre class = 'prettyprint lang-r'>par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dnbinom(c(0:10),size=2,prob=0.1)
plot(x=c(0:10),y=dnbinom(c(0:10),size=2,prob=0.1),
  ylim=c(0,1),xlim=c(-1,11),xlab=&quot;x&quot;,
  main=&quot;Función de probabilidad\n BN(n=2,p=0.1)&quot;)
lines(x=rep(0:10,each=2),y=aux, type = &quot;h&quot;, lty = 2,col=&quot;blue&quot;)
curve(pnbinom(x,size=2,prob=0,1),
  xlim=c(-1,11),col=&quot;blue&quot;,
  main=&quot;Función de distribución\n BN(n=2,p=0.1)&quot;)
par(mfrow=c(1,1))</pre>

</article></slide><slide class=""><hgroup><h2>Gráficas de la binomial negativa con R</h2></hgroup><article  id="gráficas-de-la-binomial-negativa-con-r-1">

<p>El siguiente código de R dibuja las función de probabilidad y la de distribución de una \(BN(n=2,p=0.1)\)</p>

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-33-1.png" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficas interactivas binomial negativa</h2></hgroup><article  id="gráficas-interactivas-binomial-negativa">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

<p>O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a></p>

</article></slide><slide class=""><hgroup><h2>Gráficos de la binomial negativa con python</h2></hgroup><article  id="gráficos-de-la-binomial-negativa-con-python">

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Buscad en los manuales de python cómo se dibuja la función de probabilidad y de distribución de una binomial. negativa</p></div>

<div class="exercise-sol">
<p>Necesitamos de nuevo más librerías</p>

<pre class = 'prettyprint lang-python'>import numpy as np
from scipy.stats import nbinom
import matplotlib.pyplot as plt</pre></div>

</article></slide><slide class=""><hgroup><h2>Gráficos de la binomial negativa con python</h2></hgroup><article  id="gráficos-de-la-binomial-negativa-con-python-1">

<pre class = 'prettyprint lang-python'>n, p = 10, 0.25
x = np.arange(0,nbinom.ppf(0.99, n, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, nbinom.pmf(x, n, p), &#39;bo&#39;, ms=5, label=&#39;nbinom pmf&#39;)
ax.vlines(x, 0, nbinom.pmf(x, n, p), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, nbinom.cdf(x, n, p), &#39;bo&#39;, ms=5, label=&#39;nbinom pmf&#39;)
ax.vlines(x, 0, nbinom.cdf(x, n, p), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle(&#39;Distribucion Binomial Negativa&#39;)
plt.show()</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos de la binomial negativa con python</h2></hgroup><article  id="gráficos-de-la-binomial-negativa-con-python-2">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/negativa_py_show-1.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Ejercicio: Acceso aleatorio a un sistema con triple clave.</h2></hgroup><article  id="ejercicio-acceso-aleatorio-a-un-sistema-con-triple-clave.">

<div class="exercise">
<p><strong>Sistema con tres claves de acceso</strong></p>

<p>Supongamos que tenemos un sistema informático tiene un programa de seguridad que genera accesos con claves de 3 dígitos \(000,001,\ldots 999\). En total 1000 posibilidades.</p>

<p>Como una clave de tres dígitos es fácil de romper proponemos considerar tres claves consecutivas de acceso al sistema, cada una de 3 dígitos.</p>

<p>Para acceder al sistema hay que dar las tres claves de forma consecutiva y por orden.</p>

<p>Es decir hasta que no averiguamos la primera clave no pasamos a la segunda clave.</p>

<p>Supongamos que cada vez que ponemos las dos claves olvidamos el resultado y seguimos poniendo claves al azar hasta adivinar la contraseña.</p>

<p>Así hasta conseguir entrar en el sistema.</p>

<p>Sea \(X\) la v.a que nos da el número de fallos antes de entrar en el sistema.</p></div>

</article></slide><slide class=""><hgroup><h2>Ejercicio acceso aleatorio a un sistema con triple clave.</h2></hgroup><article  id="ejercicio-acceso-aleatorio-a-un-sistema-con-triple-clave.-1">

<div class="exercise">
<p>Estamos interesados en modelar este problema. La preguntas son:</p>

<ol>
<li>¿Cuál es la distribución de probabilidad de \(X\), la v.a que nos da el número de fallos antes de acceder al sistema.</li>
<li>¿Cuál es la función de probabilidad y de distribución del \(X\)?</li>
<li>¿Cuál es la probabilidad de fallar 150 veces antes de acceder en el sistema?</li>
<li>¿Cuál es la probabilidad de fallar más de 150 veces antes de entrar en el sistema?</li>
<li>¿Cuál es el número esperado de fallos antes de acceder al sistema? ¿Y su varianza?</li>
</ol></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(r,p)\)</h2></hgroup><article  id="ejemplo-bnrp">

<div class="exercise-sol">
<p><strong>Solución 1.</strong> ¿Cuál es la distribución de probabilidad de \(X\), la v.a que nos da el número de fallos antes de acceder al sistema?</p>

<p>Bajo estados condiciones tenemos que la probabilidad de &ldquo;éxito&rdquo; de cada intento es \(p=\frac{1}{1000}=0.001\). Y como cada vez <em>olvidamos</em> en los dígitos cada intento será independiente del anterior.</p>

<p>Así que la variable \(X\) cuenta el número de fracasos independientes hasta conseguir 3 éxitos en un experimento \(Ber(p=0.001)\) por lo tanto \(X\) sigue un distribución \(BN(n=3,p=0.001).\)</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(BN(r,p)\)</h2></hgroup><article  id="ejemplo-bnrp-1">

<div class="exercise-sol">
<p><strong>Solución 2.</strong> ¿Cuál es la función de probabilidad y de distribución del \(X\)</p>

<p>En general la función de probabilidad de una \(BN(n,p)\) es</p>

<p>\[
P_X(X=x)=P(X=x)=
\left\{
\begin{array}{cc} 
{x+n-1\choose n-1} \cdot (1-p)^{x}\cdot p^n &amp; \mbox{si }  x=0,1,\ldots \\ 0 &amp; \mbox{en otro caso.}\end{array}\right.
\] En particular la función de probabilidad de una \(BN(n=3,p=0.001)\) es</p>

<p>\[
P_X(X=x)=P(X=x)=
\left\{
\begin{array}{cc} 
{x+2\choose 2} \cdot 0.999^{x}\cdot 0.001^3 &amp; \mbox{si }  x=0,1,2,\ldots \\ 0 &amp; \mbox{en otro caso.}\end{array}\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Solución ejemplo \(BN(n=3,p=0.001)\)</h2></hgroup><article  id="solución-ejemplo-bnn3p0.001">

<div class="exercise-sol">


<p><strong>Solución 3.</strong> ¿Cuál es la probabilidad de fallar 150 veces antes de acceder en el sistema?</p>

<p>Nos piden</p>

<p>\[
P(X=150)= {152\choose 2} \cdot 0.999^{150}\cdot 0.001^3
\]</p>

<p>Lo calcularemos operando con R</p>

<pre class = 'prettyprint lang-r'>choose(152,2)*0.999^150*0.001^3</pre>

<pre >## [1] 9.876743e-06</pre>

<p>con la función de R</p>

<pre class = 'prettyprint lang-r'>dnbinom(150,size=3,p=0.001)</pre>

<pre >## [1] 9.876743e-06</pre>

</article></slide><slide class=""><hgroup><h2>Solución ejemplo \(BN(n=3,p=0.001)\)</h2></hgroup><article  id="solución-ejemplo-bnn3p0.001-1">

<div class="exercise-sol">
<p><strong>Solución 3.</strong> ¿Cuál es la probabilidad de fallar 150 veces antes de acceder en el sistema?</p>

<p>Nos piden</p>

<p>\[
P(X=150)= {152\choose 2} \cdot 0.999^{150}\cdot 0.001^3
\]</p>

<p>Pero también lo podemos hacer con python</p>

<pre class = 'prettyprint lang-python'>from  scipy.special import binom
binom(152,2)*0.999**150*0.001**3</pre>

<pre >## 9.876743459670526e-06</pre>

<pre class = 'prettyprint lang-python'>nbinom.pmf(150,n=3,p=0.001)</pre>

<pre >## 9.876743459670217e-06</pre></div>

</article></slide><slide class=""><hgroup><h2>Solución ejemplo \(BN(n,p)\)</h2></hgroup><article  id="solución-ejemplo-bnnp">

<div class="example-sol">
<p><strong>Solución 4.</strong> ¿Cuál es la probabilidad de fallar más de 150 veces antes de entrar en el sistema?</p>

<p>\[P(X&gt;150)=1-P(X\leq 150)\]</p>

<p>Calculemos \(P(X\leq 150)\)</p>

<p>\[
\begin{eqnarray*}
P(X\leq 150) &amp;=&amp; P(X=0)+P(X=1)+P(X=2)+\ldots+P(X=150)= \sum_{k=0}^{150} {k+3-1\choose 3-1} \cdot (0.999)^{k}\cdot 0.001^3\\
&amp;=&amp; \ldots = 5.2320035\times 10^{-4}
\end{eqnarray*}
\]</p>

<pre class = 'prettyprint lang-r'>pnbinom(150,3,0.001)</pre>

<pre >## [1] 0.0005232003</pre>

<pre class = 'prettyprint lang-python'>nbinom.cdf(150,n=3,p=0.001)</pre>

<pre >## 0.0005232003490824058</pre></div>

</article></slide><slide class=""><hgroup><h2>Solución ejemplo \(BN(n,p)\)</h2></hgroup><article  id="solución-ejemplo-bnnp-1">

<div class="example-sol">
<p>El valor pedido será pues: \[
P(X&gt;150)=1-P(X\leq 150)=1-5.2320035\times 10^{-4}=0.9994768.
\] Vemos que es muy probable que fallemos más de 150 veces antes de entrar en el sistema.</p></div>

</article></slide><slide class=""><hgroup><h2>Solución ejemplo \(BN(n,p)\)</h2></hgroup><article  id="solución-ejemplo-bnnp-2">

<div class="example-sol">
<p><strong>Solución 5.</strong> ¿Cuál es el número esperado de fallos antes de acceder al sistema? ¿Y su desviación típica?</p>

<p>\[E(X)=n\cdot \frac{1-p}{p}=3\cdot \frac{1- 0.001}{0.001}=2997.\] \[Var(X)=n\cdot \frac{1-p}{p^2}=3\cdot \frac{1- 0.001^2}{0.001^2}=2.997\times 10^{6}.\]</p>

<p>Con python</p>

<pre class = 'prettyprint lang-python'>params = nbinom.stats(n=3,p=0.001,moments=&#39;mv&#39;)
print(&quot;E(X) = {m}&quot;.format(m=params[0]))</pre>

<pre >## E(X) = 2997.0</pre>

<pre class = 'prettyprint lang-python'>print(&quot;Var(X) = {v}&quot;.format(v=params[1]))</pre>

<pre >## Var(X) = 2997000.0</pre></div>

</article></slide><slide class=""><hgroup><h2>¿Tres claves de tres dígitos o una de 9 dígitos?</h2></hgroup><article  id="tres-claves-de-tres-dígitos-o-una-de-9-dígitos">

<div class="exercise">
<p><strong>Ejercicio</strong></p>

<p>Supongamos que ponemos una sola clave de 9 dígitos. Estudiemos en este caso la variable aleatoria que da el número de fallos antes de entrar en el sistema y comparemos los resultados.</p></div>

<div class="exercise-sol">
<p>Si seguimos suponiendo que cada vez ponemos la contraseña al azar pero esta vez con una clave de 9 dígitos. La probabilidad de éxito será ahora \(p=\frac{1}{10^{9}}\).</p>

<p>Si llamamos \(X_9\) a la variable aleatoria que nos da el número de fallos antes de entra en el sistema seguirá una distribución \(Ge(p=\frac{1}{10^9}=0.000000001)\).</p></div>

</article></slide><slide class=""><hgroup><h2>Qué da más seguridad ¿tres claves de tres dígitos o una de 9 dígitos?</h2></hgroup><article  id="qué-da-más-seguridad-tres-claves-de-tres-dígitos-o-una-de-9-dígitos">

<div class="exercise-sol">
<p>Su valor esperado es</p>

<p>\[
E(X_9)=\frac{1-p}{p}=\frac{1-0.000000001}{0.000000001}=10\times 10^{8}.
\]</p>

<p>\(1000 000 000\) son 1000 millones de fallos esperados hasta abrir la puerta.</p>

<p>Recordemos que con tres contraseñas de 3 dígitos el valor esperado de fallos es</p>

<p>\[3\cdot \frac{1-0.001}{0.001}=2997.\]</p>

<p>Por lo tanto, desde el punto de vista de la seguridad, es mejor una clave larga de 9 dígitos que tres cortas si escribimos las contraseñas al azar.</p></div>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribución de Poisson</h2></hgroup><article  id="distribución-de-poisson">

</article></slide><slide class=""><hgroup><h2>Distribución Poisson</h2></hgroup><article  id="distribución-poisson">

<p>Diremos que una v.a. discreta \(X\) con \(X(\Omega)=\mathbf{N}\) tiene distribución de Poisson con parámetro \(\lambda&gt;0\), y lo denotaremos por \(Po(\lambda)\) si su función de probabilidad es:</p>

<p>\[
P_{X}(x)=P(X=x)=
\left\{\begin{array}{ll}
\frac{\lambda^x}{x!} e^{-\lambda}&amp; \mbox{ si } x=0,1,\ldots\\
0 &amp; \mbox{en otro caso}\end{array}\right..
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución Poisson</h2></hgroup><article  id="distribución-poisson-1">

<p>Usando que el desarrollo en serie de Taylor de la función exponencial es \[
e^{\lambda}=\sum_{x=0}^{+\infty} \frac{\lambda^x}{x!},
\] es fácil comprobar que la suma de la función de probabilidad en todos los valores del dominio de \(X\), o sea, los enteros positivos, vale 1.</p>

<p>Además recordemos que dado \(x\in\mathbb{R}-\{0\}\) se tiene que</p>

<p>\[
\lim_{n\to\infty} \left(1+\frac{x}{n}\right)^n=e^x.
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución Poisson</h2></hgroup><article  id="distribución-poisson-2">

<p>Usando la expresión anterior para \(x=-\lambda\), tenemos:</p>

<p>\[
\lim_{n\to\infty} \left(1-\frac{\lambda}{n}\right)^n=\lim_{n\to\infty} \left(1+\frac{-\lambda}{n}\right)^n=e^{-\lambda}.
\]</p>

</article></slide><slide class=""><hgroup><h2>La distribución de Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-de-poisson-como-límite-de-una-binomial.">

<p>La distribución de Poisson (<a href='https://es.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson' title=''>Siméon Denis Poisson</a>) aparece en el conteo de determinados eventos que se producen en un intervalo de tiempo o en el espacio.</p>

<p>Supongamos que nuestra variable de interés es \(X\), el número de eventos en el intervalo de tiempo \((0,t]\), como por ejemplo el número de llamadas a un <em>call center</em> en una hora donde suponemos que se cumplen las siguientes condiciones:</p>

</article></slide><slide class=""><hgroup><h2>La distribución Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-poisson-como-límite-de-una-binomial.">

<ol>
<li>El número promedio de eventos en el intervalo \((0,t]\) es \(\lambda&gt;0\).</li>
<li>Es posible dividir el intervalo de tiempo en un gran número de subintervalos (denotemos por \(n\) al número de intervalos) de forma que:

<ul>
<li>La probabilidad de que se produzcan dos o más eventos en un subintervalo es despreciable.</li>
<li>El número de ocurrencias de eventos en un intervalo es independiente del número de ocurrencias en otro intervalo.</li>
<li>La probabilidad de que un evento ocurra en un subintervalo es \(p_n=\frac{\lambda}{n}\)·</li>
</ul></li>
</ol>

</article></slide><slide class=""><hgroup><h2>La distribución Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-poisson-como-límite-de-una-binomial.-1">

<p>Bajo estas condiciones, podemos considerar que el número de eventos en el intervalo \((0,t]\) será el número de &ldquo;éxitos&rdquo; en \(n\) repeticiones independientes de un proceso Bernoulli de parámetro \(p_n\)</p>

<p>Entonces si \(n\to\infty\) y \(p_n\cdot n\) se mantiene igual a \(\lambda\) resulta que la función de probabilidad de \(X\) se puede escribir como</p>

</article></slide><slide class=""><hgroup><h2>La distribución Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-poisson-como-límite-de-una-binomial.-2">

<p>\[
\begin{array}{rl}
P(X_n=k)&amp;=\left(\begin{array}{c} n\\ k\end{array}\right) \cdot p_n^k\cdot  (1-p_n)^{n-k}
\\
&amp;= {n\choose k}\cdot \left(\frac{\lambda}{n}\right)^{k}\cdot \left(1-\frac{\lambda}{n}\right)^{n-k}\\
&amp;=
\frac{\lambda^k}{k!}\cdot\frac{n!}{(n-k)!\cdot n^k}\cdot
\left(1-\frac{\lambda}{n}\right)^{n}\cdot \left(1-\frac{\lambda}{n}\right)^{-k}.
\end{array}
\]</p>

</article></slide><slide class=""><hgroup><h2>La distribución Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-poisson-como-límite-de-una-binomial.-3">

<p>Si hacemos tender \(n\) hacia \(\infty\), obtenemos: \[
\lim_{n\to \infty} P(X_n=k) = \lim_{n\to \infty} \frac{\lambda^k}{k!}\cdot\frac{n!}{(n-k)!\cdot n^k} \cdot
\left(1-\frac{\lambda}{n}\right)^{n}\cdot \left(1-\frac{\lambda}{n}\right)^{-k}.
\]</p>

<p>Calculemos el límite de algunos de los factores de la expresión</p>

<p>\[
\displaystyle\lim_{n\to \infty}\frac{n!}{(n-k)!\cdot n^k}= \lim_{n\to \infty}\frac{n\cdot (n-1)\cdots (n-k-1)}{n^k}
=\lim_{n\to \infty}\frac{n^{k}+\cdots}{n^k}=1.
\]</p>

</article></slide><slide class=""><hgroup><h2>La distribución Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-poisson-como-límite-de-una-binomial.-4">

<p>\[
\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^{n}=e^{-\lambda}
\]</p>

<p>Y también teniendo en cuanta que \(k\) es constante.</p>

<p>\[
\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^{-k}=\lim_{n\to \infty} 1^{-k}=\lim_{n\to \infty}  1=1.
\]</p>

</article></slide><slide class=""><hgroup><h2>La distribución Poisson como &ldquo;límite&rdquo; de una binomial.</h2></hgroup><article  id="la-distribución-poisson-como-límite-de-una-binomial.-5">

<p>Para acabar</p>

<p>\[
\displaystyle\lim_{n\to\infty} P(X_n=k)=
\lim_{n\to\infty} \left(\begin{array}{c} n\\ k\end{array}\right)
\cdot p_n^k \cdot (1-p_n)^{n-k}= \frac{\lambda^k}{k!}\cdot 1 \cdot e^{-\lambda}\cdot 1=\frac{\lambda^k}{k!}\cdot e^{-\lambda}.
\]</p>

<p>Lo que confirma que límite de una serie de variables \(B(n,p_n=\frac{\lambda}{n})\) sigue una ley \(Po(\lambda)\).</p>

</article></slide><slide class=""><hgroup><h2>Procesos de Poisson</h2></hgroup><article  id="procesos-de-poisson">

<p>Lo interesante de las variables Poisson es que podemos modificar (si el modelo lo permite) el intervalo de tiempo \((0,t]\) en el que contamos los eventos.</p>

<p>Claro que esto no tiene que poder ser así.</p>

<p>Pero en general si la variable es poisson en \((0,t]\) también lo será en cualquier subintervalo \((0,t&#39;]\) para todo \(t&#39;\) tal que \(0&lt;t&#39;&lt;t\).</p>

<p>Así que podremos definir una serie de variables \(X_t\) de distribución \(Po(\lambda\cdot t)\).</p>

</article></slide><slide class=""><hgroup><h2>Procesos de Poisson</h2></hgroup><article  id="procesos-de-poisson-1">

<p><l class="prop"> Definición procesos de Poisson </l></p>

<p>Consideremos un experimento <em>Poisson</em> con \(\lambda\) igual al promedio de eventos en una unidad de tiempo (u.t.).</p>

<p>Si \(t\) es una cantidad de tiempo en u.t., la v.a. \(X_{t}\)=numero de eventos en el intervalo \((0,t]\) es una \(Po(\lambda\cdot t)\).</p>

<p>El conjunto de variables \(\{X_t\}_{t&gt;0}\) recibe el nombre de <strong>proceso de Poisson</strong>.</p>

</article></slide><slide class=""><hgroup><h2>Resumen distribución Poisson \(X\equiv Po(\lambda)\)</h2></hgroup><article  id="resumen-distribución-poisson-xequiv-polambda">

<table class = 'rmdtable'>
<col width="50.000000%" />
<col width="50.000000%" />
<tr class="header">
<th align="right">\(X\) Poisson</th>
<th align="left">\(\lambda\)</th>
</tr>
<tr class="odd">
<td align="right">\(D_X=\)</td>
<td align="left">\(\{0,1,\ldots \}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(x)=P(X=x)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} \frac{\lambda^x}{x!}e^{-\lambda} &amp; \mbox{ si } x=0,1,\ldots\\ 0 &amp; \mbox{ en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq X)=\)</td>
<td align="left">\(\begin{array}{l}\left\{\begin{array}{ll} 0 &amp; \mbox{si } x&lt;0\\\displaystyle\sum_{i=0}^{k} P(X=i)= \displaystyle\sum_{i=0}^{k} \frac{\lambda^i}{i!}\cdot e^{-\lambda} &amp; \mbox{si }\left\{\begin{array}{l}k\leq x&lt; k+1\\k=0,1,2,\ldots\end{array}\right.\end{array}\right. \\\mbox{Calcular la suma o utilizar funciones de R o python.} \end{array}\)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=\lambda\)</td>
<td align="left">\(Var(X)=\lambda\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Resumen proceso Poisson \(X_t\equiv Po(\lambda\cdot t)\)</h2></hgroup><article  id="resumen-proceso-poisson-x_tequiv-polambdacdot-t">

<table class = 'rmdtable'>
<col width="50.000000%" />
<col width="50.000000%" />
<tr class="header">
<th align="right">\(X_t\) \(Po(\lambda\cdot t)\)</th>
<th align="left">\(\lambda\) promedio por u.t.</th>
</tr>
<tr class="odd">
<td align="right">\(D_X=\)</td>
<td align="left">\(\{0,1,\ldots \}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(x)=P(X=x)=\)</td>
<td align="left">\(\left\{\begin{array}{ll} \frac{(\lambda\cdot t)^x}{x!}e^{-\lambda\cdot t} &amp; \mbox{ si } x=0,1,\ldots\\ 0 &amp; \mbox{ en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq X)=\)</td>
<td align="left">\(\begin{array}{l}\left\{\begin{array}{ll} 0 &amp; \mbox{si } x&lt;0\\\displaystyle\sum_{i=0}^{k} P(X=i)= \displaystyle\sum_{i=0}^{k} \frac{(\lambda\cdot t)^i}{i!}\cdot e^{-\lambda\cdot t} &amp; \mbox{si }\left\{\begin{array}{l}k\leq x&lt; k+1\\k=0,1,2,\ldots\end{array}\right.\end{array}\right. \\\mbox{Calcular la suma o utilizar funciones de R o python.} \end{array}\)</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=\lambda\cdot t\)</td>
<td align="left">\(Var(X)=\lambda\cdot t\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Aproximación de la distribución binomial por la Poisson</h2></hgroup><article  id="aproximación-de-la-distribución-binomial-por-la-poisson">

<p>Bajo el punto de vista anterior y si \(p\) es pequeño y \(n\) suficientemente grande la distribución \(B(n,p)\) se aproxima a una \(Po(\lambda=n\cdot p)\).</p>

<p>Existen distintos criterios (ninguno perfecto) de cuando la aproximación es buena.</p>

<p>Por ejemplo si</p>

<p>\[n\geq 20\mbox{ o mejor }n\geq 30, n\cdot p &lt; 10 \mbox{ y } p\leq 0.05,\]</p>

<p>la aproximación de una \(B(n,p)\) por una \(Po(n\cdot p)\) es buena. Sobre todo para los valores cercanos a \(E(X)=\lambda\).</p>

</article></slide><slide class=""><hgroup><h2>Gráficos aproximación binomial Poisson (Interactivos)</h2></hgroup><article  id="gráficos-aproximación-binomial-poisson-interactivos">

<p>Condición deseable \(n\geq 20\), \(n\cdot p &lt; 10\), \(p\leq 0.05\)</p>

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

<p>O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a></p>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda">

<div class="example">
<p><strong>Ejemplo</strong>: Trampa insectos.</p>

<p>La conocida <a href='https://es.wikipedia.org/wiki/Insecticida_el%C3%A9ctrico' title=''>lámpara antiinsectos o insecticida eléctrico</a> atrae a los insectos voladores con una luz ultravioleta y los mata por electrocución.</p>

<p>Consideremos la v.a. \(X\) que cuenta el número de insectos caídos en la trampa en una hora. Supongamos que el número promedio de insectos que captura la trampa en una hora es \(E(X)=20\) y que podemos admitir que \(X\) sigue una ley de probabilidad \(Po(\lambda=20)\).</p>

<p>Nos piden</p>

<ol>
<li>Comentar de forma breve si se cumplen intuitivamente las condiciones para tener una distribución Poisson.</li>
<li>Escribir de forma explicita la función de probabilidad y de distribución de \(X\).</li>
<li>Calculad la probabilidad de que en una hora caigan en la trampa exactamente 21 insectos.</li>
<li>Calculad la probabilidad de que en una hora caigan en la trampa al menos 6 insectos.</li>
<li>¿Cuál es el valor esperando, la varianza y la desviación típica de \(X\)?</li>
</ol></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda-1">

<div class="example-sol">
<p><strong>Solución 1.</strong> Comentar de forma breve si se cumplen intuitivamente las condiciones para tener una distribución Poisson.</p>

<ol>
<li>El número promedio de eventos en el intervalo \((0,1]\), una hora es \(\lambda=20&gt;0\).</li>
<li>Es posible dividir el intervalo de tiempo de una hora en un gran número de subintervalos (denotemos por \(n\) al número de intervalos) de forma que:

<ul>
<li>La probabilidad de que se produzcan dos o más electrocuciones un subintervalo es despreciable. No es posible que dos mosquitos se electrocuten al mismo tiempo.</li>
<li>El número de ocurrencias, electrocuciones de insectos, en un intervalo es independiente del número de electrocuciones en otro intervalo.</li>
<li>La probabilidad de que un evento ocurra en un subintervalo es \(p_n=\frac{\lambda}{n}\)· Podemos dividir los 20 insectos promedio entre los \(n\) intervalos (trozo de hora) de forma que \(p_n=\frac{\lambda}{n}\).</li>
<li>Por ejemplo si \(n=60\) tenemos que \(p_n=\frac{20}{60}=\frac{1}{3}\). La probabilidad de que en un minuto la trampa chisporrotee es \(\frac{1}{3}\).</li>
</ul></li>
</ol></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda-2">

<div class="example-sol">
<p><strong>Solución 2.</strong> Escribid de forma explicita la función de probabilidad y de distribución de \(X\).</p>

<p>La distribución de probabilidad de un \(Po(\lambda)\) es</p>

<p>\[
P_X(x)=P(X=x)=\left\{\begin{array}{ll}  \frac{\lambda^x}{x!}e^{-\lambda} &amp; \mbox{ si } x=0,1,\ldots\\ 0  &amp; \mbox{ en otro caso.}\end{array}\right.
\]</p>

<p>En nuestro caso, \(\lambda =20\):</p>

<p>\[
P_X(x)=P(X=x)=\left\{\begin{array}{ll}\frac{20^x}{x!}e^{-20} &amp; \mbox{ si } x=0,1,\ldots\\ 0  &amp; \mbox{ en otro caso.}\end{array}\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda-3">

<div class="example-sol">
<p>La función de distribución es</p>

<p>\[
F_X(x)=P(X\leq X)=
\left\{\begin{array}{ll} 
0 &amp; \mbox{si } x&lt;0\\
\displaystyle\sum_{i=0}^{k} P(X=i)=\sum_{i=0}^{k}\frac{\lambda^i}{i!}\cdot e^{-\lambda} &amp; \mbox{si  }
\left\{\begin{array}{l}
k\leq x&lt; k+1\\k=0,1,2,\ldots
\end{array}
\right.
\end{array}
\right.
\]</p>

<p>En nuestro caso \[
F_X(x)=P(X\leq X)=
\left\{\begin{array}{ll} 
0 &amp; \mbox{si } x&lt;0\\
\displaystyle\sum_{i=0}^{k} P(X=i)=\sum_{i=0}^{k}\frac{20^i}{i!}\cdot e^{-20} &amp; \mbox{si  }
\left\{\begin{array}{l}
k\leq x&lt; k+1\\k=0,1,2,\ldots
\end{array}
\right.
\end{array}
\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda-4">

<div class="example-sol">
<p><strong>Solución 3.</strong> Calculad la probabilidad de que en una hora caigan en la trampa exactamente 21 insectos.</p>

<p>Nos piden la probabilidad siguiente: \[
P(X=21)=\frac{20^{21}}{21!} e^{-20}=0.0846051.
\]</p>

<p>Para realizar el cálculo anterior, podemos usar <code>R</code> como calculadora o usar la función <code>dpois</code> que nos calcula la función de distribución de la variable de Poisson:</p>

<pre class = 'prettyprint lang-r'>20^21/factorial(21)*exp(-20)</pre>

<pre >## [1] 0.08460506</pre>

<pre class = 'prettyprint lang-r'>dpois(21,lambda = 20)</pre>

<pre >## [1] 0.08460506</pre></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda-5">

<div class="example-sol">
<p><strong>Solución 4.</strong> Calculad la probabilidad de que en una hora caigan en la trampa al menos 6 insectos.</p>

<p>Nos piden la probabilidad siguiente: \[
\begin{array}{rl}
 P(X\geq 6)&amp;=1- P(X&lt;6)=1-P(X\leq 5)=1-F_X(5)=1-\displaystyle\sum_{x=0}^{5} \frac{20^{x}}{x!}\cdot e^{-20}\\
 &amp;=
 1-\left(\frac{20^{0}}{0!}\cdot e^{-20}+\frac{20^{1}}{1!}\cdot e^{-20}+\frac{20^{2}}{2!}\cdot e^{-20}+\frac{20^{3}}{3!}\cdot e^{-20}+\frac{20^{4}}{4!}\cdot e^{-20}+\frac{20^{5}}{5!}\cdot e^{-20}\right)\\
 &amp;=
 1-e^{-20}\cdot \left(1+20+\frac{400}{4}+\frac{8000}{6}+\frac{160000}{24}+\frac{3200000}{120}\right)\\
 &amp;=
 1-e^{-20} \cdot \left(\frac{1 \cdot 120+20\cdot 120+400\cdot 30+8000\cdot 20+160000\cdot 24+3200000\cdot 1}{120}\right)\\
 &amp;= 1-e^{-20}\cdot\left(\frac{4186520}{120}\right)=1-7.1908841\times 10^{-5} =0.9999281.
\end{array}
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo \(Po(\lambda)\)</h2></hgroup><article  id="ejemplo-polambda-6">

<div class="example-sol">
<p><strong>Solución 5.</strong> ¿Cuál es el valor esperado, la varianza y la desviación típica de \(X\)?</p>

<p>El valor esperado del número de insectos caídos en la trampa en una hora es</p>

<p>\[E(X)=\lambda=20\]</p>

<p>Su varianza es \[Var(X)=\lambda=20\]</p>

<p>y su desviación típica vale \[\sqrt{Var(X)}=+\sqrt{\lambda}=+\sqrt{20}=4.47214.\]</p></div>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-4">

<p>Consideremos por ejemplo una v.a. \(X\) con distribución \(Po(\lambda=3)\). Calculemos \(P_X(0)=P(X=0), P_X(1)=P(X=1)\) con <code>R</code>:</p>

<pre class = 'prettyprint lang-r'>dpois(0,lambda = 3)</pre>

<pre >## [1] 0.04978707</pre>

<pre class = 'prettyprint lang-r'>dpois(1,lambda = 3)</pre>

<pre >## [1] 0.1493612</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-5">

<p>Si quisiéramos hallar la función de distribución en los mismos valores anteriores, \(F_X(0)=P(X\leq 0), F_X(1)=P(X\leq 1)\), haríamos lo siguiente:</p>

<pre class = 'prettyprint lang-r'>ppois(0,lambda = 3)</pre>

<pre >## [1] 0.04978707</pre>

<pre class = 'prettyprint lang-r'>ppois(1,lambda = 3)</pre>

<pre >## [1] 0.1991483</pre>

<pre class = 'prettyprint lang-r'>dpois(0,lambda = 3)+dpois(1,lambda = 3) ## es igual a ppois(1,lambda=3)</pre>

<pre >## [1] 0.1991483</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-6">

<p>A continuación, comprobemos que \(F_X(10)=\sum\limits_{x=0}^{10} P_X(x)\):</p>

<pre class = 'prettyprint lang-r'>dpois(0:10,3)</pre>

<pre >##  [1] 0.0497870684 0.1493612051 0.2240418077 0.2240418077 0.1680313557
##  [6] 0.1008188134 0.0504094067 0.0216040315 0.0081015118 0.0027005039
## [11] 0.0008101512</pre>

<pre class = 'prettyprint lang-r'>sum(dpois(0:10,3))</pre>

<pre >## [1] 0.9997077</pre>

<pre class = 'prettyprint lang-r'>ppois(10,3)</pre>

<pre >## [1] 0.9997077</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos distribución Poisson con R</h2></hgroup><article  id="cálculos-distribución-poisson-con-r">

<p>Si quisiéramos generar una secuencia de \(100\) observaciones para una distribución de Poisson de parámetro \(\lambda=3\), \(Po(3)\), tendríamos que hacer:</p>

<pre class = 'prettyprint lang-r'>rpois(n=100,lambda = 3)</pre>

<pre >##   [1] 2 5 3 3 2 2 5 2 4 4 2 3 2 2 2 2 2 3 3 5 3 3 2 4 2 3 2 1 1 3 4 6 2 5 3 4 1
##  [38] 1 6 3 4 1 4 3 4 3 0 2 1 4 3 0 2 4 2 3 5 2 1 3 3 4 2 5 0 3 1 1 4 6 4 5 0 4
##  [75] 0 3 3 3 4 1 2 6 2 2 2 2 1 2 5 2 5 3 7 3 5 2 3 2 1 3</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-7">

<div class="exercise">
<p><strong>Ejercicio de la trampa para insectos (continuación)</strong></p>

<p>En el ejercicio de la trampa para insectos teníamos que \(X\) es una \(Po(20)\). Responded con R a la preguntas 3 y 4 de este ejercicio</p></div>

<div class="example-sol">
<p><strong>Pregunta 3.</strong> Calculad la probabilidad de que en una hora caigan en la trampa exactamente 21 insectos.</p>

<p>Recordemos que la probabilidad pedida es \(P(X=21)\):</p>

<pre class = 'prettyprint lang-r'>dpois(21,lambda=20)# P(X=21)</pre>

<pre >## [1] 0.08460506</pre></div>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-8">

<div class="example-sol">
<p><strong>Pregunta 4.</strong> Calculad la probabilidad de que en una hora caigan en la trampa al menos 6 insectos.</p>

<p>Recordemos que la probabilidad pedida es \(P(X\geq 6)=1-P(X&lt;6)=1-P(X\leq 5)\):</p>

<pre class = 'prettyprint lang-r'>ppois(5,lambda=20)</pre>

<pre >## [1] 7.190884e-05</pre>

<pre class = 'prettyprint lang-r'>1-ppois(5,lambda=20) # es 1-P(X&lt;=5)=P(X&gt;=6)</pre>

<pre >## [1] 0.9999281</pre>

<pre class = 'prettyprint lang-r'>ppois(5,lambda=20,lower.tail =FALSE ) # acumula hacia arriba P(X&gt;5)=P(X&gt;=6)=P(X=6)+P(X=7)+...</pre>

<pre >## [1] 0.9999281</pre></div>

</article></slide><slide class=""><hgroup><h2>Gráficos de la distribución Poisson con R</h2></hgroup><article  id="gráficos-de-la-distribución-poisson-con-r">

<pre class = 'prettyprint lang-r'>lambda=20
par(mfrow=c(1,2))
n=qpois(0.99,lambda=lambda)
aux=rep(0,(n+1)*2)
aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)
ymax=max(ppois(0:n,lambda=lambda))
plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),
     ylim=c(0,ymax),xlim=c(-1,n+1),xlab=&quot;x&quot;,ylab=&quot;Función de probabilidad&quot;,
     main=paste0(c(&quot;Función de probabilidad\n  Po(lambda=&quot;,lambda,&quot;)&quot;),collapse = &quot;&quot;))
lines(x=rep(0:n,each=2),y=aux,pch=21, type = &quot;h&quot;, lty = 2,col=&quot;blue&quot;)
curve(ppois(x,lambda=lambda),
      xlim=c(-1,n+1),col=&quot;blue&quot;,ylab=&quot;Función de Distribución&quot;,
      main=paste0(c(&quot;Función de distribución \n Po(lambda=&quot;,lambda,&quot;)&quot;),collapse = &quot;&quot;))
par(mfrow=c(1,1))</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos de la distribución Poisson con R</h2></hgroup><article  id="gráficos-de-la-distribución-poisson-con-r-1">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/graficosPOISON-1.png" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficos interactivos con R</h2></hgroup><article  id="gráficos-interactivos-con-r">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

<p>O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a></p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-6">

<p>Sea \(X\) un una v.a. \(Po(\lambda=3)\). Entonces</p>

<p>\(P_X(0)=P(X=0), P_X(1)=P(X=1)\) en este orden son</p>

<pre class = 'prettyprint lang-python'>from scipy.stats import poisson
poisson.pmf(0,mu = 3)</pre>

<pre >## 0.049787068367863944</pre>

<pre class = 'prettyprint lang-python'>poisson.pmf(1,mu = 3)</pre>

<pre >## 0.14936120510359185</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-7">

<p>Sea \(X\) un una v.a. \(Po(\lambda=3)\). Entonces</p>

<p>\(F_X(0)=P(X\leq 0), F_X(1)=P(X\leq 1)\) en este orden son</p>

<pre class = 'prettyprint lang-python'>poisson.cdf(0,mu = 3)</pre>

<pre >## 0.04978706836786395</pre>

<pre class = 'prettyprint lang-python'>poisson.cdf(1,mu = 3)</pre>

<pre >## 0.1991482734714558</pre>

<pre class = 'prettyprint lang-python'>poisson.pmf(0,mu = 3)+poisson.pmf(1,mu= 3) ## es igual a poisson.cdf(1,lambda=3)</pre>

<pre >## 0.1991482734714558</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-8">

<p>Por ejemplo podemos comprobar que \(F_X(10)=\displaystyle\sum_{0}^{10} P_X(x)\)</p>

<pre class = 'prettyprint lang-python'>range(0,10)</pre>

<pre >## range(0, 10)</pre>

<pre class = 'prettyprint lang-python'>poisson.pmf(range(0,10),mu=3)</pre>

<pre >## array([0.04978707, 0.14936121, 0.22404181, 0.22404181, 0.16803136,
##        0.10081881, 0.05040941, 0.02160403, 0.00810151, 0.0027005 ])</pre>

<pre class = 'prettyprint lang-python'>sum(poisson.pmf(range(0,10),mu=3))</pre>

<pre >## 0.9988975118698846</pre>

<pre class = 'prettyprint lang-python'>poisson.cdf(10,mu=3)</pre>

<pre >## 0.9997076630493527</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-9">

<div class="exercise">
<p>En el ejercicio de la trampa para insectos teníamos que \(X\) es una \(Po(20)\). Responded con python a la preguntas 3 y 4 de este ejercicio</p></div>

<div class="example-sol">
<p><strong>Pregunta 3.</strong> Calculad la probabilidad de que en una hora caigan en la trampa exactamente 21 insectos.</p>

<p>La respuesta a la pregunta 3 es calcular \(P(X=21)\)</p>

<pre class = 'prettyprint lang-python'>poisson.pmf(21,mu=20)
# P(X=21)</pre>

<pre >## 0.08460506418293791</pre></div>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-10">

<div class="example-sol">
<p><strong>Pregunta 4.</strong> Calculad la probabilidad de que en una hora caigan en la trampa al menos 6 insectos.</p>

<p>La pregunta 4 nos pide calcular \(P(X\geq 6)=1-P(X\leq 5)\)</p>

<pre class = 'prettyprint lang-python'>1-poisson.cdf(5,mu=20) 
# es 1-P(X&lt;=5)=P(X&gt;=6)</pre>

<pre >## 0.9999280911594716</pre></div>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-11">

<p>Como ya hemos visto con <code>scipy.stats</code> podemos pedir los momentos de una variable aleatoria \(Po(3)\)</p>

<pre class = 'prettyprint lang-python'>poisson.stats(mu=3, moments=&#39;mv&#39;)</pre>

<pre >## (array(3.), array(3.))</pre>

<p>Y también generar secuencias de observaciones aleatorias de una población \(Po(3)\)</p>

<pre class = 'prettyprint lang-python'>poisson.rvs(mu=3,size=40)</pre>

<pre >## array([4, 0, 1, 2, 7, 5, 2, 2, 3, 1, 4, 4, 1, 1, 4, 2, 0, 4, 2, 0, 5, 2,
##        2, 3, 4, 4, 2, 3, 4, 2, 3, 2, 3, 1, 4, 0, 4, 1, 0, 4])</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos con python</h2></hgroup><article  id="gráficos-con-python-2">

<p><font size="3"></p>

<pre class = 'prettyprint lang-python'>from scipy.stats import poisson
mu = 10 # mu = lambda
x = np.arange(poisson.ppf(0.01, mu),poisson.ppf(0.99, mu))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, poisson.pmf(x, mu), &#39;bo&#39;, ms=5, label=&#39;poisson pmf&#39;)
ax.vlines(x, 0, poisson.pmf(x, mu), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, poisson.cdf(x, mu), &#39;bo&#39;, ms=5, label=&#39;poisson cdf&#39;)
ax.vlines(x, 0, poisson.cdf(x, mu), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle(&#39;Distribucion de Poisson&#39;)
plt.show()</pre>

<p></font></p>

</article></slide><slide class=""><hgroup><h2>Gráficos con python</h2></hgroup><article  id="gráficos-con-python-3">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_poiss2-1.png" width="480" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficos interactivos proceso \(Po(\lambda\cdot t\))</h2></hgroup><article  id="gráficos-interactivos-proceso-polambdacdot-t">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

<p>O en este <a href='https://joanby.shinyapps.io/DistribucionesNotables/' title=''>página del servidor de shiny</a></p>

</article></slide><slide class=""><hgroup><h2>Ejemplo proceso Poisson</h2></hgroup><article  id="ejemplo-proceso-poisson">

<div class="example">
<p><strong>Número de impactos de insectos en la visera de un casco</strong></p>

<p>Un colega de trabajo, al que llamaremos JG, es muy aficionado a los grandes premios de velocidad tanto en coches como en motos.</p>

<p>Como es tan aficionado está obsesionado con muchas de las más extravagantes estadísticas de estos deportes. En particular le propusimos que estudiara el número de insectos que chocan contra la visera de un casco de un motorista GP o de un conductor de fórmula 1 .</p>

<p>La idea es que el número de insectos está igualmente repartido por todo el circuito y de promedio impactan \(\lambda&gt;0\) insectos por minuto. También es razonable suponer que:</p>

<ul>
<li>podemos dividir la superficie de la visera en cuadrados suficientemente pequeños de forma que la probabilidad de que caigan dos insectos en la misma zona es prácticamente 0.</li>
<li>la probabilidad de que un insecto impacte en un cuadrado cualquiera de la visera es independiente de cualquier otro cuadrado.</li>
<li>si hemos dividido la visera en \(n\) cuadrados la probabilidad \(p_n\) de impacto de un cuadrado vale \(p_n=\frac{\lambda}{n}\).</li>
</ul>

<p>Bajo estas condiciones, si denotamos por \(X_t\) como el número de insectos que ha impactado en la visera en el intervalo \((0,t]\) (en \(t\) minutos), podemos afirmar que \(X_t\) es un proceso de Poisson \(Po(\lambda\cdot t)\).</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo proceso Poisson</h2></hgroup><article  id="ejemplo-proceso-poisson-1">

<div class="exercise-sol">
<p>Supongamos que nos dicen que \(\lambda=3\) insectos por minuto. Entonces el proceso de poisson \(X_t\) seguirá un ley \(Po(3\cdot t).\)</p>

<p>Ahora estamos en condiciones de preguntar al proceso de Poisson.</p>

<p>¿Cuál es la probabilidad de que en 10 minutos impacten más de 25 insectos?</p>

<p>En este caso \(t=10\) \(X_{10}\)= número de insectos que impactan en 10 minutos, el intervalo \([0,10)\) que sigue una \(P(3\cdot 10=30)\). Por lo tanto</p>

<p>\[P(X&gt;25)=1-P(X\leq 25)\]</p>

<p>lo resolvemos con R</p>

<pre class = 'prettyprint lang-r'>1-ppois(25,lambda=30)</pre>

<pre >## [1] 0.7916426</pre></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo proceso Poisson</h2></hgroup><article  id="ejemplo-proceso-poisson-2">

<div class="exercise-sol">
<p>Otra pregunta interesante es que tengamos que esperar más de 2 minutos para observar el primer impacto</p>

<p>\[P(X_2=0)=\frac{(3\cdot 2)^0}{0!}\cdot e^{-3\cdot 2}= e^{-6}=0.002479.\]</p>

<p>Con R</p>

<pre class = 'prettyprint lang-r'>6^0/factorial(0)*exp(-6)</pre>

<pre >## [1] 0.002478752</pre>

<pre class = 'prettyprint lang-r'>ppois(0,lambda=3*2)</pre>

<pre >## [1] 0.002478752</pre></div>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Distribución hipergeométrica</h2></hgroup><article  id="distribución-hipergeométrica">

</article></slide><slide class=""><hgroup><h2>Modelo de la distribución hipergeométrica</h2></hgroup><article  id="modelo-de-la-distribución-hipergeométrica">

<p>Supongamos que disponemos de una urna de de sorteos que contiene \(m\) bolas blancas y \(n\) bolas rojas.</p>

<p>En total en esta urna hay \(m+n\) bolas, \(m\) blancas y \(n\) rojas. Si extraemos dos bolas de la urna lo podemos hacer de dos formas:</p>

<ul>
<li>Extraer una anotar su color y reponerla. Sacar otra y anotar su color. Hemos extraído la bola con reposición.</li>
<li>Extraer simultáneamente dos bolas (sin reposición) y contar el número de bolas blancas.</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Modelo de la distribución hipergeométrica</h2></hgroup><article  id="modelo-de-la-distribución-hipergeométrica-1">

<p>Sea \(X\) es la v.a. que cuenta el número de bolas blancas extraídas.</p>

<ul>
<li>En el primer caso, \(X\) es una \(B(n=2,p=\frac{m}{m+n})\) ya que consiste en repetir dos veces el mismo experimento de Bernoulli.</li>
<li>En el segundo caso, \(X\) sigue una distribución hipergeométrica que estudiaremos en esta sección.</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Modelo de la distribución hipergeométrica</h2></hgroup><article  id="modelo-de-la-distribución-hipergeométrica-2">

<p><l class="definition"> Distribución hipergeométrica </l></p>

<p>Sean \(n\), \(m\) y \(k\) tres número enteros positivos y tales que \(k&lt;m+n\).</p>

<p>Consideremos una urna que contiene \(m+n\) bolas de las que \(m\) son blancas y las restantes \(n\) no (son no blancas).</p>

<p>El número total de bolas es \(m+n\). Extraemos de forma aleatoria \(k\) bolas de la urna sin reemplazarlas.</p>

</article></slide><slide class=""><hgroup><h2>Modelo de la distribución hipergeométrica</h2></hgroup><article  id="modelo-de-la-distribución-hipergeométrica-3">

<p>Sea \(X\) la v.a. que cuenta el número de bolas blancas extraídas. Diremos que la distribución de \(X\) es hipergeométrica de parámetros \(m\), \(n\) y \(k\) y la denotaremos por \(H(m,n,k)\).</p>

<p>Su dominio es</p>

<p>\[D_X=\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq  x \leq \min\{m,k\}\right\}\]</p>

<p>Para explicarlo, veamos varios ejemplos:</p>

<ul>
<li>\(H(m=5,n=2,k=3)\). Tenemos \(m=5\) bolas blancas, \(n=2\) no blancas y sacamos \(k=3\) bolas sin reposición.

<ul>
<li>En este caso el mínimo de bolas blancas extraídas es \(1=k-n=3-2\), ya que sólo hay dos no blancas.</li>
<li>En cambio, el máximo si es \(k=3\), ya que tenemos bolas blancas de &ldquo;sobra&rdquo;.</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Modelo de la distribución hipergeométrica</h2></hgroup><article  id="modelo-de-la-distribución-hipergeométrica-4">

<p>\[D_X=\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq  x \leq \min\{m,k\}\right\}\]</p>

<ul>
<li>\(H(m=2,n=5,k=3)\). Tenemos \(m=2\) bolas blancas, \(n=5\) no blancas y sacamos \(k=3\) bolas sin reposición.

<ul>
<li>En este caso el mínimo de bolas blancas es \(0\) ya que puedo sacar 3 no blancas.</li>
<li>En cambio, el máximo si es \(m=2\), ya que aunque saquemos \(k=3\) bolas, al llegar a 2 ya hemos extraído todas las bolas blancas de la urna.</li>
</ul></li>
<li>\(H(m=10,n=10,k=3)\). Tenemos \(m=10\) bolas blancas, \(n=10\) no blancas y sacamos \(k=3\) bolas sin reposición.

<ul>
<li>En este caso podemos obtener desde \(0\) blancas hasta \(k=3\) blancas.</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Modelo de la distribución hipergeométrica</h2></hgroup><article  id="modelo-de-la-distribución-hipergeométrica-5">

<p>Su función de probabilidad es:</p>

<p>Su función de probabilidad es: \[
P_{X}(x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}}, &amp; \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\}, \mbox { para  } x\in \mathbf{N},\\
0,  &amp; \mbox{en otro caso.}\end{array}\right.
\]</p>

</article></slide><slide class=""><hgroup><h2>Distribución hipergeométrica</h2></hgroup><article  id="distribución-hipergeométrica-1">

<p><l class="observ"> <strong>Observación: otras parametrizaciones</strong> </l></p>

<p>En ocasiones se parametriza una v.a. hipergeométrica mediante \(N=m+n\), número total de bolas, \(k\), número de extracciones y \(p\), probabilidad de extraer una bola blanca.</p>

<p>Así podemos <strong>parametrizar alternativamente</strong> la distribución hipergeométrica así</p>

<p>\[H(N,k,p)\mbox{ donde } p=\frac{m}{N}.\]</p>

</article></slide><slide class=""><hgroup><h2>Resumen hipergeométrica \(H(m,n,k)\).</h2></hgroup><article  id="resumen-hipergeométrica-hmnk.">

<table class = 'rmdtable'>
<col width="50.000000%" />
<col width="50.000000%" />
<tr class="header">
<th align="right">\(X=\)número de bolas blancas en \(k\) extracciones sin reposición de una urna con \(m\) bolas blancas y \(n\) negras.</th>
<th align="left">\(H(m,n,k)\)</th>
</tr>
<tr class="odd">
<td align="right">\(D_X\)=</td>
<td align="left">\(\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq x \leq \min\{m,k\}\right\}\)</td>
</tr>
<tr class="even">
<td align="right">\(P_X(x)=P(X=x)=\)</td>
<td align="left">\(\left\{ \begin{array}{ll} \frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}}, &amp; \mbox{ si } \max\{0,k-n\}\leq x \leq \min\{m,k\}, \\ 0, &amp; \mbox{en otro caso.}\end{array}\right.\)</td>
</tr>
<tr class="odd">
<td align="right">\(F_X(x)=P(X\leq x)\)</td>
<td align="left">Hay que sumarla. Utilizad funciones de <code>R</code> o de python.</td>
</tr>
<tr class="even">
<td align="right">\(E(X)=\frac{k\cdot m}{m+n}\)</td>
<td align="left">\(Var(X)=k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}\)</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Ejemplo clásico urna \(m=15\) blancas, \(n=10\) rojas y \(k=3\) extracciones sin reposición.</h2></hgroup><article  id="ejemplo-clásico-urna-m15-blancas-n10-rojas-y-k3-extracciones-sin-reposición.">

<div class="example">
<p><strong>Urna con bolas blancas y rojas</strong></p>

<p>Tenemos una urna con 15 bolas blancas y 10 bolas rojas. Extraemos al azar tres bolas de la urna sin reposición. Sea \(X\) el número de bolas <strong>blancas</strong> extraídas. Bajo esta condiciones, la v.a. \(X\) sigue una ley de distribución \(H(m=15,n=10,k=3)\).</p></div>

<div class="example-sol">
<p>La función de probabilidad es</p>

<p>\[
P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}} &amp; \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\} \mbox { para  } x\in \mathbf{N}\\
0  &amp; \mbox{en otro caso}\end{array}\right.
\]</p>

<p>Sustituyendo los parámetros obtenemos</p>

<p>\[
P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{15}{x}\cdot \binom{10}{3-x}}{\binom{25}{3}} &amp; \mbox{ si }
0\leq x \leq 3 \mbox { para  } x\in \mathbf{N}\\
0  &amp; \mbox{en otro caso}\end{array}\right.
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo clásico urna \(m=15\) blancas, \(n=10\) rojas y \(k=3\) extracciones sin reposición.</h2></hgroup><article  id="ejemplo-clásico-urna-m15-blancas-n10-rojas-y-k3-extracciones-sin-reposición.-1">

<div class="example-sol">
<p>La probabilidad de sacar 2 blancas será</p>

<p>\[
P(X=2)=\frac{\binom{15}{2}\cdot \binom{10}{3-2}}{\binom{25}{3}}
\]</p>

<pre class = 'prettyprint lang-r'>c(choose(15,2), choose(10,1), choose(25,3))</pre>

<pre >## [1]  105   10 2300</pre>

<p>\(P(X=2)=\frac{105\cdot10 }{2300}=0.4565217.\)</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo clásico urna \(m=15\) blancas, \(n=10\) rojas y \(k=3\) extracciones sin reposición.</h2></hgroup><article  id="ejemplo-clásico-urna-m15-blancas-n10-rojas-y-k3-extracciones-sin-reposición.-2">

<div class="example-sol">
<p>La probabilidad de que saquemos más de 1 bola blanca es</p>

<p>\[
\begin{array}{rl}
P(X&gt; 1)&amp;= 1-P(X\leq 1)=1-(P(X=0)+P(X=1))\\
&amp;=
1-\left(\frac{\binom{15}{0}\cdot \binom{10}{3}}{\binom{25}{3}}+
\frac{\binom{15}{1}\cdot \binom{10}{2}}{\binom{25}{3}}\right)\\
&amp;=
1-\left(
\frac{1\cdot120 }{2300}+\frac{15\cdot45 }{2300}
\right)=1-\frac{120+15\cdot 45}{2300}=0.6543478.
\end{array}
\]</p></div>

</article></slide><slide class=""><hgroup><h2>Ejemplo clásico urna \(m=15\) blancas, \(n=10\) rojas y \(k=3\) extracciones sin reposición.</h2></hgroup><article  id="ejemplo-clásico-urna-m15-blancas-n10-rojas-y-k3-extracciones-sin-reposición.-3">

<div class="example-sol">


<p>El número esperado de bolas blancas extraídas para una v.a. \(X\) \(H(m=15,n=10,k=3)\) es</p>

<p>\[E(X)=\frac{k\cdot m}{m+n}=\frac{3\cdot 15}{15+10}=\frac{45}{35}=1.285714.\]</p>

<p>La varianza vale: \[
\begin{array}{rl}
Var(X)&amp;=k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}\\
&amp;=3\cdot\frac{15}{15+10}\cdot\left(1-\frac{15}{15+10}\right) \cdot\frac{15+10-3}{15+10-1}\\
&amp;=
3\cdot\frac{15}{25}\cdot\left(1-\frac{15}{25}\right) \cdot\frac{22}{24}= 
3\cdot\frac{15}{25}\cdot\frac{25-15}{25} \cdot\frac{22}{24}\\
&amp;=
3\cdot\frac{15}{25}\cdot\frac{10}{25}\cdot\frac{22}{24}=0.66.
\end{array}
\]</p>

<p>Y por lo tanto su desviación típica es</p>

<p>\[
+\sqrt{Var(X)}=+\sqrt{0.66}=0.812404.
\]</p>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-9">

<p>Sea \(X\) una v.a. \(H(m,n,k)\). La función de <code>R</code> para calcular la función de probabilidad en un valor \(x\), \(P(X=x)\), es <code>dhyper(x,m,n,k)</code> y para calcular la función de distribución en un valor \(q\), \(P(X\leq q)\), es <code>phyper(q,m,n,k)</code>. Para generar una muestra de valores que siga la distribución \(H(m,n,k)\), hay que usar la función <code>rhyper(nn,m,n,k)</code> donde <code>nn</code> es el número de observaciones aleatorias deseado de la muestra.</p>

<p>Por ejemplo, si \(X\) es una \(H(m=15,n=10,k=3)\), los valores de \(P(X=2)\) y que \(P(X&gt;1)=1-P(X\leq 1)\) son:</p>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-10">

<pre class = 'prettyprint lang-r'>dhyper(x=2,m=15,10,k=3)</pre>

<pre >## [1] 0.4565217</pre>

<pre class = 'prettyprint lang-r'>phyper(q=1,m=15,n=10,k=3)# sí, le han puesto q ya veremos el porqué</pre>

<pre >## [1] 0.3456522</pre>

<pre class = 'prettyprint lang-r'>1-phyper(q=1,m=15,n=10,k=3)</pre>

<pre >## [1] 0.6543478</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con R</h2></hgroup><article  id="cálculos-con-r-11">

<p>Una muestra aleatoria de este experimento de tamaño 200 sería:</p>

<pre class = 'prettyprint lang-r'>rhyper(nn=200,m=15,n=10,k=3)</pre>

<pre >##   [1] 2 3 1 3 1 2 2 3 2 2 1 2 1 2 2 3 3 1 1 1 1 0 2 3 2 1 3 2 2 2 2 3 2 3 3 2 0
##  [38] 1 2 1 3 2 2 3 2 3 2 2 3 2 3 1 2 2 2 2 3 2 2 1 3 2 2 3 1 2 2 2 2 2 3 0 2 0
##  [75] 3 2 2 2 1 2 2 3 1 1 1 2 2 2 2 1 1 3 2 2 3 2 2 1 1 1 3 3 2 2 2 1 3 2 2 2 1
## [112] 1 2 3 2 2 1 2 2 2 2 2 2 3 1 2 3 3 1 1 2 2 1 1 3 2 1 1 2 2 3 1 1 1 2 1 1 3
## [149] 1 2 2 3 3 2 3 1 2 1 2 2 2 1 2 3 1 3 3 3 2 2 1 3 3 1 1 2 2 2 2 2 3 2 1 2 1
## [186] 1 1 1 2 1 1 2 2 2 2 3 3 1 0 2</pre>

</article></slide><slide class=""><hgroup><h2>Gráficas con R</h2></hgroup><article  id="gráficas-con-r">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/unnamed-chunk-55-1.png" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Gráficos interactivos \(H(m,n,k)\)</h2></hgroup><article  id="gráficos-interactivos-hmnk">

<p>Para ver las gráficas interactivas abrir con Rstudio Distribuciones_Notables_1_INTERACTIVO_RUN_Rstudio.Rmd</p>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-12">

<p>Sea \(X\) una \(H(m,n,k)\), las funciones de <code>scipy.stats</code> cambian los parámetros</p>

<ul>
<li>\(M\) es el número total de bolas. Con nuestra parametrización \(M=m+n\).</li>
<li>\(n\) es el número de bolas blancas. Con nuestra parametrización \(n=m\).</li>
<li>\(N\) es el número de extracciones. Con nuestra parametrización \(N=k\).</li>
</ul>

<pre class = 'prettyprint lang-python'>from scipy.stats import hypergeom</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-13">

<pre class = 'prettyprint lang-python'>hypergeom.pmf(1,M=15+10,n=15,N=3)</pre>

<pre >## 0.29347826086956585</pre>

<pre class = 'prettyprint lang-python'>hypergeom.cdf(1,M=15+10,n=15,N=3)</pre>

<pre >## 0.3456521739130442</pre>

<pre class = 'prettyprint lang-python'>1-hypergeom.cdf(1,M=15+10,n=15,N=3)</pre>

<pre >## 0.6543478260869557</pre>

</article></slide><slide class=""><hgroup><h2>Cálculos con python</h2></hgroup><article  id="cálculos-con-python-14">

<p>Una muestra aleatoria de este experimento sería…</p>

<pre class = 'prettyprint lang-python'>hypergeom.rvs(M=15+10,n=15,N=3,size=100)</pre>

<pre >## array([2, 0, 1, 3, 2, 2, 3, 3, 2, 2, 2, 0, 2, 2, 2, 1, 3, 3, 1, 1, 3, 1,
##        2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 2, 3, 1, 3, 1, 2, 1,
##        3, 2, 2, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 2, 2, 1, 1, 1, 2, 3,
##        2, 2, 3, 1, 2, 1, 1, 2, 3, 2, 2, 1, 3, 0, 3, 2, 2, 1, 1, 3, 0, 0,
##        2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3])</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos con python</h2></hgroup><article  id="gráficos-con-python-4">

<pre class = 'prettyprint lang-python'>from scipy.stats import hypergeom
[M, n, N] = [20, 7, 12] ##20 elementos, 7 del tipo, extraemos 12
x = np.arange(max(0, N-M+n),min(n, N))
fig =plt.figure(figsize=(5, 2.7))
 =ax = fig.add_subplot(1,2,1)
 =ax.plot(x, hypergeom.pmf(x, M, n, N), &#39;bo&#39;, ms=5, label=&#39;hypergeom pmf&#39;)
 =ax.vlines(x, 0, hypergeom.pmf(x, M, n, N), colors=&#39;b&#39;, lw=2, alpha=0.5)
 =ax.set_ylim([0, max(hypergeom.pmf(x, M, n, N))*1.1])
for tick in ax.xaxis.get_major_ticks():
   =tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  =tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
 =ax.plot(x, hypergeom.cdf(x, M, n, N), &#39;bo&#39;, ms=5, label=&#39;hypergeom cdf&#39;)
 =ax.vlines(x, 0, hypergeom.cdf(x, M, n, N), colors=&#39;b&#39;, lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
   =tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
   =tick.label.set_fontsize(5)
 =fig.suptitle(&#39;Distribucion Hipergeometrica&#39;)
 =plt.show()</pre>

</article></slide><slide class=""><hgroup><h2>Gráficos con python</h2></hgroup><article  id="gráficos-con-python-5">

<p><img src="Distribuciones_Notables_1_No_interactivo_files/figure-html/py_hyper2-1.png" width="480" /></p></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
